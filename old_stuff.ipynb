{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "239d8234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "surrogates = ['BNN', 'RF', 'GP', 'DE']\n",
    "exp_dict = {'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "results_dict = {surrogate:copy.deepcopy(exp_dict) for surrogate in surrogates}\n",
    "directory=\"./results_real_data/results_mnist\"\n",
    "for foldername in os.listdir(directory):\n",
    "    folder = os.path.join(directory, foldername)\n",
    "    if os.path.isdir(folder):\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.find(\"parameters\") != -1:\n",
    "                json_file = open(os.path.join(folder, filename))\n",
    "                params = json.load(json_file)\n",
    "            elif filename.find(\"metrics\") != -1:\n",
    "                json_file = open(os.path.join(folder, filename))\n",
    "                metrics = json.load(json_file)\n",
    "        if params['bo'] == True and params['acquisition']==\"EI\":\n",
    "            results_dict[params['surrogate']]['inst_regret_test'].append(metrics['y_regret_test'])\n",
    "            results_dict[params['surrogate']]['inst_regret_pool'].append(metrics['y_regret_pool'])\n",
    "            results_dict[params['surrogate']]['tot_regret_test'].append(np.cumsum(metrics['y_regret_test']))\n",
    "            results_dict[params['surrogate']]['tot_regret_pool'].append(np.cumsum(metrics['y_regret_pool']))\n",
    "            results_dict[params['surrogate']]['x_opt_dist_pool'].append(metrics['x_y_opt_dist_pool'])\n",
    "            results_dict[params['surrogate']]['x_opt_dist_test'].append(metrics['x_y_opt_dist_test'])\n",
    "            results_dict[params['surrogate']]['sharpness'].append(metrics['mean_sharpness'])\n",
    "            results_dict[params['surrogate']]['calibration_mse'].append(metrics['y_calibration_mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f55d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = {'surrogate':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for surrogate in surrogates:\n",
    "    column_names['surrogate'].append(surrogate)\n",
    "    column_names['inst_regret_test'].append(np.array(results_dict[surrogate]['inst_regret_test']).mean(axis=0)[-1])\n",
    "    column_names['inst_regret_pool'].append(np.array(results_dict[surrogate]['inst_regret_pool']).mean(axis=0)[-1])\n",
    "    column_names['tot_regret_test'].append(np.array(results_dict[surrogate]['tot_regret_test']).mean(axis=0)[-1])\n",
    "    column_names['tot_regret_pool'].append(np.array(results_dict[surrogate]['tot_regret_pool']).mean(axis=0)[-1])\n",
    "    column_names['calibration_mse'].append(np.array(results_dict[surrogate]['calibration_mse']).mean(axis=0)[-1])\n",
    "    column_names['sharpness'].append(np.array(results_dict[surrogate]['sharpness']).mean(axis=0)[-1])\n",
    "    column_names['x_opt_dist_test'].append(np.array(results_dict[surrogate]['x_opt_dist_test']).mean(axis=0)[-1])\n",
    "    column_names['x_opt_dist_pool'].append(np.array(results_dict[surrogate]['x_opt_dist_pool']).mean(axis=0)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "816234e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surrogate</th>\n",
       "      <th>inst_regret_test</th>\n",
       "      <th>inst_regret_pool</th>\n",
       "      <th>tot_regret_test</th>\n",
       "      <th>tot_regret_pool</th>\n",
       "      <th>calibration_mse</th>\n",
       "      <th>sharpness</th>\n",
       "      <th>x_opt_dist_test</th>\n",
       "      <th>x_opt_dist_pool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BNN</td>\n",
       "      <td>0.077776</td>\n",
       "      <td>0.076023</td>\n",
       "      <td>7.855349</td>\n",
       "      <td>7.678342</td>\n",
       "      <td>0.070897</td>\n",
       "      <td>0.082350</td>\n",
       "      <td>2.379112</td>\n",
       "      <td>2.287373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>1.440757</td>\n",
       "      <td>1.258007</td>\n",
       "      <td>0.010766</td>\n",
       "      <td>-0.677659</td>\n",
       "      <td>1.915892</td>\n",
       "      <td>0.363764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.003479</td>\n",
       "      <td>1.924739</td>\n",
       "      <td>1.747732</td>\n",
       "      <td>0.008575</td>\n",
       "      <td>-0.379879</td>\n",
       "      <td>1.700792</td>\n",
       "      <td>0.892353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>1.371771</td>\n",
       "      <td>1.188781</td>\n",
       "      <td>0.031632</td>\n",
       "      <td>0.012249</td>\n",
       "      <td>1.915892</td>\n",
       "      <td>0.363764</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  surrogate  inst_regret_test  inst_regret_pool  tot_regret_test  \\\n",
       "0       BNN          0.077776          0.076023         7.855349   \n",
       "1        RF          0.002111          0.000119         1.440757   \n",
       "2        GP          0.005231          0.003479         1.924739   \n",
       "3        DE          0.002111          0.000119         1.371771   \n",
       "\n",
       "   tot_regret_pool  calibration_mse  sharpness  x_opt_dist_test  \\\n",
       "0         7.678342         0.070897   0.082350         2.379112   \n",
       "1         1.258007         0.010766  -0.677659         1.915892   \n",
       "2         1.747732         0.008575  -0.379879         1.700792   \n",
       "3         1.188781         0.031632   0.012249         1.915892   \n",
       "\n",
       "   x_opt_dist_pool  \n",
       "0         2.287373  \n",
       "1         0.363764  \n",
       "2         0.892353  \n",
       "3         0.363764  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(column_names)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba3b5d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "surrogates = ['BNN', 'RF', 'GP', 'DE']\n",
    "exp_dict = {'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "results_dict = {surrogate:copy.deepcopy(exp_dict) for surrogate in surrogates}\n",
    "directory=\"./results_real_data/results_mnist\"\n",
    "for foldername in os.listdir(directory):\n",
    "    folder = os.path.join(directory, foldername)\n",
    "    if os.path.isdir(folder):\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.find(\"parameters\") != -1:\n",
    "                json_file = open(os.path.join(folder, filename))\n",
    "                params = json.load(json_file)\n",
    "            elif filename.find(\"metrics\") != -1:\n",
    "                json_file = open(os.path.join(folder, filename))\n",
    "                metrics = json.load(json_file)\n",
    "        if params['bo'] == True and params['acquisition'] != 'RS':\n",
    "            results_dict[params['surrogate']]['inst_regret_test'].append(metrics['y_regret_test'])\n",
    "            results_dict[params['surrogate']]['inst_regret_pool'].append(metrics['y_regret_pool'])\n",
    "            results_dict[params['surrogate']]['tot_regret_test'].append(np.cumsum(metrics['y_regret_test']))\n",
    "            results_dict[params['surrogate']]['tot_regret_pool'].append(np.cumsum(metrics['y_regret_pool']))\n",
    "            results_dict[params['surrogate']]['x_opt_dist_pool'].append(metrics['x_y_opt_dist_pool'])\n",
    "            results_dict[params['surrogate']]['x_opt_dist_test'].append(metrics['x_y_opt_dist_test'])\n",
    "            results_dict[params['surrogate']]['calibration_mse'].append(metrics['y_calibration_mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf4548a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = {'surrogate':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for surrogate in surrogates:\n",
    "    column_names['surrogate'].append(surrogate)\n",
    "    column_names['inst_regret_test'].append(np.array(results_dict[surrogate]['inst_regret_test']).mean(axis=0)[-1])\n",
    "    column_names['inst_regret_pool'].append(np.array(results_dict[surrogate]['inst_regret_pool']).mean(axis=0)[-1])\n",
    "    column_names['tot_regret_test'].append(np.array(results_dict[surrogate]['tot_regret_test']).mean(axis=0)[-1])\n",
    "    column_names['tot_regret_pool'].append(np.array(results_dict[surrogate]['tot_regret_pool']).mean(axis=0)[-1])\n",
    "    column_names['calibration_mse'].append(np.array(results_dict[surrogate]['calibration_mse']).mean(axis=0)[-1])\n",
    "    column_names['sharpness'].append(np.array(results_dict[surrogate]['calibration_mse']).mean(axis=0)[-1])\n",
    "    column_names['x_opt_dist_test'].append(np.array(results_dict[surrogate]['x_opt_dist_test']).mean(axis=0)[-1])\n",
    "    column_names['x_opt_dist_pool'].append(np.array(results_dict[surrogate]['x_opt_dist_pool']).mean(axis=0)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fed04684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surrogate</th>\n",
       "      <th>inst_regret_test</th>\n",
       "      <th>inst_regret_pool</th>\n",
       "      <th>tot_regret_test</th>\n",
       "      <th>tot_regret_pool</th>\n",
       "      <th>calibration_mse</th>\n",
       "      <th>sharpness</th>\n",
       "      <th>x_opt_dist_test</th>\n",
       "      <th>x_opt_dist_pool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BNN</td>\n",
       "      <td>0.043067</td>\n",
       "      <td>0.041314</td>\n",
       "      <td>5.705066</td>\n",
       "      <td>5.528060</td>\n",
       "      <td>0.074766</td>\n",
       "      <td>0.074766</td>\n",
       "      <td>1.692949</td>\n",
       "      <td>1.942210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.009024</td>\n",
       "      <td>0.007192</td>\n",
       "      <td>1.956949</td>\n",
       "      <td>1.778028</td>\n",
       "      <td>0.007368</td>\n",
       "      <td>0.007368</td>\n",
       "      <td>2.135600</td>\n",
       "      <td>1.461835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>1.890339</td>\n",
       "      <td>1.713332</td>\n",
       "      <td>0.010138</td>\n",
       "      <td>0.010138</td>\n",
       "      <td>1.617271</td>\n",
       "      <td>1.099050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DE</td>\n",
       "      <td>0.004678</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>1.603955</td>\n",
       "      <td>1.424236</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>1.848996</td>\n",
       "      <td>0.906883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  surrogate  inst_regret_test  inst_regret_pool  tot_regret_test  \\\n",
       "0       BNN          0.043067          0.041314         5.705066   \n",
       "1        RF          0.009024          0.007192         1.956949   \n",
       "2        GP          0.004946          0.003193         1.890339   \n",
       "3        DE          0.004678          0.002766         1.603955   \n",
       "\n",
       "   tot_regret_pool  calibration_mse  sharpness  x_opt_dist_test  \\\n",
       "0         5.528060         0.074766   0.074766         1.692949   \n",
       "1         1.778028         0.007368   0.007368         2.135600   \n",
       "2         1.713332         0.010138   0.010138         1.617271   \n",
       "3         1.424236         0.027473   0.027473         1.848996   \n",
       "\n",
       "   x_opt_dist_pool  \n",
       "0         1.942210  \n",
       "1         1.461835  \n",
       "2         1.099050  \n",
       "3         0.906883  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(column_names)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2ac1995f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "surrogates = ['BNN', 'RF', 'GP', 'DE']\n",
    "acquisitions = ['EI', 'RS', 'UCB']\n",
    "exp_dict = {'acquisition':[],'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "results_dict = {surrogate:{acquisition:copy.deepcopy(exp_dict) for acquisition in acquisitions} for surrogate in surrogates}\n",
    "directory=\"./results_mnist\"\n",
    "for foldername in os.listdir(directory):\n",
    "    folder = os.path.join(directory, foldername)\n",
    "    if os.path.isdir(folder):\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.find(\"parameters\") != -1:\n",
    "                json_file = open(os.path.join(folder, filename))\n",
    "                params = json.load(json_file)\n",
    "            elif filename.find(\"metrics\") != -1:\n",
    "                json_file = open(os.path.join(folder, filename))\n",
    "                metrics = json.load(json_file)\n",
    "        if params['bo'] == True:\n",
    "            results_dict[params['surrogate']][params['acquisition']]['inst_regret_test'].append(metrics['y_regret_test'])\n",
    "            results_dict[params['surrogate']][params['acquisition']]['inst_regret_pool'].append(metrics['y_regret_pool'])\n",
    "            results_dict[params['surrogate']][params['acquisition']]['tot_regret_test'].append(np.cumsum(metrics['y_regret_test']))\n",
    "            results_dict[params['surrogate']][params['acquisition']]['tot_regret_pool'].append(np.cumsum(metrics['y_regret_pool']))\n",
    "            results_dict[params['surrogate']][params['acquisition']]['x_opt_dist_pool'].append(metrics['x_y_opt_dist_pool'])\n",
    "            results_dict[params['surrogate']][params['acquisition']]['x_opt_dist_test'].append(metrics['x_y_opt_dist_test'])\n",
    "            results_dict[params['surrogate']][params['acquisition']]['calibration_mse'].append(metrics['y_calibration_mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "c48f17be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pg/8kgknkg97zgbj393j1nl2gdh0000gn/T/ipykernel_29043/3934684622.py:12: RuntimeWarning: Mean of empty slice.\n",
      "  column_names['sharpness'].append(np.array(result_dict['sharpness']).mean(axis=0)[-1])\n",
      "/opt/homebrew/lib/python3.10/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [171]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m column_names[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtot_regret_pool\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtot_regret_pool\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     11\u001b[0m column_names[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalibration_mse\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcalibration_mse\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m---> 12\u001b[0m column_names[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msharpness\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msharpness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     13\u001b[0m column_names[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_opt_dist_test\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_opt_dist_test\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     14\u001b[0m column_names[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_opt_dist_pool\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(result_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_opt_dist_pool\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "column_names = {'surrogate':[], 'acquisition':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for surrogate in surrogates:\n",
    "    for acq in acquisitions:\n",
    "        result_dict = results_dict[surrogate][acq]\n",
    "        column_names['surrogate'].append(surrogate)\n",
    "        column_names['acquisition'].append(acq)\n",
    "        column_names['inst_regret_test'].append(np.array(result_dict['inst_regret_test']).mean(axis=0)[-1])\n",
    "        column_names['inst_regret_pool'].append(np.array(result_dict['inst_regret_pool']).mean(axis=0)[-1])\n",
    "        column_names['tot_regret_test'].append(np.array(result_dict['tot_regret_test']).mean(axis=0)[-1])\n",
    "        column_names['tot_regret_pool'].append(np.array(result_dict['tot_regret_pool']).mean(axis=0)[-1])\n",
    "        column_names['calibration_mse'].append(np.array(result_dict['calibration_mse']).mean(axis=0)[-1])\n",
    "        column_names['x_opt_dist_test'].append(np.array(result_dict['x_opt_dist_test']).mean(axis=0)[-1])\n",
    "        column_names['x_opt_dist_pool'].append(np.array(result_dict['x_opt_dist_pool']).mean(axis=0)[-1])\n",
    "#EXPLORATION PARAM IN UCB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8e87ebb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surrogate</th>\n",
       "      <th>acquisition</th>\n",
       "      <th>inst_regret_test</th>\n",
       "      <th>inst_regret_pool</th>\n",
       "      <th>tot_regret_test</th>\n",
       "      <th>tot_regret_pool</th>\n",
       "      <th>calibration_mse</th>\n",
       "      <th>sharpness</th>\n",
       "      <th>x_opt_dist_test</th>\n",
       "      <th>x_opt_dist_pool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GP</td>\n",
       "      <td>RS</td>\n",
       "      <td>0.018467</td>\n",
       "      <td>0.017053</td>\n",
       "      <td>3.343981</td>\n",
       "      <td>3.201156</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>0.001074</td>\n",
       "      <td>1.531298</td>\n",
       "      <td>2.044028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DE</td>\n",
       "      <td>RS</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>0.018199</td>\n",
       "      <td>3.528680</td>\n",
       "      <td>3.383915</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>1.949876</td>\n",
       "      <td>2.188604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>RS</td>\n",
       "      <td>0.022690</td>\n",
       "      <td>0.021216</td>\n",
       "      <td>3.950461</td>\n",
       "      <td>3.807517</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>0.002589</td>\n",
       "      <td>1.868767</td>\n",
       "      <td>1.891383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.004501</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>2.024838</td>\n",
       "      <td>1.862155</td>\n",
       "      <td>0.016751</td>\n",
       "      <td>0.016751</td>\n",
       "      <td>1.851887</td>\n",
       "      <td>1.060813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GP</td>\n",
       "      <td>EI</td>\n",
       "      <td>0.003666</td>\n",
       "      <td>0.001756</td>\n",
       "      <td>2.038871</td>\n",
       "      <td>1.885037</td>\n",
       "      <td>0.017040</td>\n",
       "      <td>0.017040</td>\n",
       "      <td>1.800995</td>\n",
       "      <td>0.971749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.005402</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>1.343570</td>\n",
       "      <td>1.176857</td>\n",
       "      <td>0.021021</td>\n",
       "      <td>0.021021</td>\n",
       "      <td>1.681376</td>\n",
       "      <td>1.204924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>EI</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>1.353766</td>\n",
       "      <td>1.167717</td>\n",
       "      <td>0.021673</td>\n",
       "      <td>0.021673</td>\n",
       "      <td>1.690952</td>\n",
       "      <td>1.201067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DE</td>\n",
       "      <td>EI</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>1.128171</td>\n",
       "      <td>0.951735</td>\n",
       "      <td>0.033327</td>\n",
       "      <td>0.033327</td>\n",
       "      <td>1.705922</td>\n",
       "      <td>0.593549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DE</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>1.113575</td>\n",
       "      <td>0.936234</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>1.717420</td>\n",
       "      <td>0.448578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BNN</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.032624</td>\n",
       "      <td>0.031050</td>\n",
       "      <td>4.966790</td>\n",
       "      <td>4.815213</td>\n",
       "      <td>0.078891</td>\n",
       "      <td>0.078891</td>\n",
       "      <td>2.119728</td>\n",
       "      <td>2.015077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>0.055401</td>\n",
       "      <td>0.053788</td>\n",
       "      <td>6.629648</td>\n",
       "      <td>6.475709</td>\n",
       "      <td>0.080848</td>\n",
       "      <td>0.080848</td>\n",
       "      <td>2.226489</td>\n",
       "      <td>2.176705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BNN</td>\n",
       "      <td>RS</td>\n",
       "      <td>0.024174</td>\n",
       "      <td>0.022760</td>\n",
       "      <td>3.976285</td>\n",
       "      <td>3.833460</td>\n",
       "      <td>0.090732</td>\n",
       "      <td>0.090732</td>\n",
       "      <td>1.810838</td>\n",
       "      <td>1.827847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   surrogate acquisition  inst_regret_test  inst_regret_pool  tot_regret_test  \\\n",
       "7         GP          RS          0.018467          0.017053         3.343981   \n",
       "10        DE          RS          0.019890          0.018199         3.528680   \n",
       "4         RF          RS          0.022690          0.021216         3.950461   \n",
       "8         GP         UCB          0.004501          0.002521         2.024838   \n",
       "6         GP          EI          0.003666          0.001756         2.038871   \n",
       "5         RF         UCB          0.005402          0.003689         1.343570   \n",
       "3         RF          EI          0.005855          0.003935         1.353766   \n",
       "9         DE          EI          0.002760          0.000888         1.128171   \n",
       "11        DE         UCB          0.002600          0.000729         1.113575   \n",
       "2        BNN         UCB          0.032624          0.031050         4.966790   \n",
       "0        BNN          EI          0.055401          0.053788         6.629648   \n",
       "1        BNN          RS          0.024174          0.022760         3.976285   \n",
       "\n",
       "    tot_regret_pool  calibration_mse  sharpness  x_opt_dist_test  \\\n",
       "7          3.201156         0.001074   0.001074         1.531298   \n",
       "10         3.383915         0.002099   0.002099         1.949876   \n",
       "4          3.807517         0.002589   0.002589         1.868767   \n",
       "8          1.862155         0.016751   0.016751         1.851887   \n",
       "6          1.885037         0.017040   0.017040         1.800995   \n",
       "5          1.176857         0.021021   0.021021         1.681376   \n",
       "3          1.167717         0.021673   0.021673         1.690952   \n",
       "9          0.951735         0.033327   0.033327         1.705922   \n",
       "11         0.936234         0.034800   0.034800         1.717420   \n",
       "2          4.815213         0.078891   0.078891         2.119728   \n",
       "0          6.475709         0.080848   0.080848         2.226489   \n",
       "1          3.833460         0.090732   0.090732         1.810838   \n",
       "\n",
       "    x_opt_dist_pool  \n",
       "7          2.044028  \n",
       "10         2.188604  \n",
       "4          1.891383  \n",
       "8          1.060813  \n",
       "6          0.971749  \n",
       "5          1.204924  \n",
       "3          1.201067  \n",
       "9          0.593549  \n",
       "11         0.448578  \n",
       "2          2.015077  \n",
       "0          2.176705  \n",
       "1          1.827847  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(column_names)\n",
    "df = df.sort_values('calibration_mse')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d1b055bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "marker_dict = {'BNN':'v', 'GP': \"o\", 'RF':'D', 'DE':'P'}\n",
    "color_dict = {'EI':'b', 'UCB':'g', 'RS':'r'}\n",
    "for index, row in df.iterrows():\n",
    "    plt.scatter(row['calibration_mse'], row['tot_regret_pool'], marker=marker_dict[row['surrogate']], color=color_dict[row['acquisition']])\n",
    "\n",
    "    \n",
    "f = lambda m,c: plt.plot([],[],marker=m, color=c, ls=\"none\")[0]\n",
    "handles = [f(\"s\", list(color_dict.values())[i]) for i in range(3)]\n",
    "handles += [f(list(marker_dict.values())[i], \"k\") for i in range(4)]\n",
    "labels = list(color_dict.keys()) + ['BNN', 'GP', 'RF', 'DE']\n",
    "\n",
    "plt.legend(handles, labels, loc=2, framealpha=1)\n",
    "plt.xlabel('Calibration MSE')\n",
    "plt.ylabel('Instantaneous Regret')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "801e2596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "#TODO: Calculate new sample distance to nearest in training data at every BO iteration.\n",
    "#TODO: Make ranking. Rank four surrogate models for one specific seed, dataset and acquistion function.\n",
    "print(len([[0.85216802945564], [0.9796499778609811], [1.7319457048592344], [1.3013670289165014], [2.6143284981069916], [1.6910675460981386], [1.1054294645425786], [1.6713345438251763], [1.2594462877514772], [1.4664952414005414], [1.8491430217748834], [1.5589459519758067], [1.4343461830747533], [1.1559642191441728], [1.3058856081035617], [0.9798185160879221], [1.3487392094452473], [1.147530457993135], [1.2109971509841404], [0.978419828645433], [1.046736991541116], [2.058772199512438], [1.0873440361036426], [0.697252708791025], [0.6957823352371522], [1.3394479037424936], [1.5496707980455158], [0.8549722777358603], [0.7800027853371898], [1.6744180536412845], [1.5767549710153015], [1.4589989930056246], [0.7789467415439548], [2.0371108974604972], [1.809532467026455], [1.2927557217621441], [1.1018294786930265], [0.7703045482111519], [1.956857982051085], [1.0873357914910455], [1.664820382767177], [1.3881243019042724], [2.005975090874568], [0.9138272732097178], [1.388651682050511], [0.9234915091057267], [1.4265814383296849], [0.8521680294556402], [0.6943258410252555], [2.1242217255186002], [0.695782335237152], [0.7687511355120255], [0.48990925804396096], [0.6972655658421145], [1.1035450546825836], [1.2105287805388734], [1.0403562456505935], [1.8633645109961772], [1.2927557217621435], [0.7786886818526499], [1.5102814427510962], [1.2446067927270115], [1.0403303944834499], [0.8481439912189138], [1.048898015517321], [1.1502072272725568], [0.4874631190904859], [0.6940621509521361], [0.7687511355120255], [1.5003069908551316], [0.7771520279852959], [1.2927765252845786], [0.9798551127792042], [0.6032713022279209], [0.7771404925809462], [0.7703161859830611], [0.8561974058476766], [1.0973360020429561], [0.48746311909048595], [1.209162945661001], [0.6015712611182606], [0.7727374418365522], [0.6972655658421144], [0.6989778665686657], [1.7714170220601826], [0.8445136968549881], [0.853805072593619], [0.9196000225419176], [1.1035450546825836], [1.4583049671035175], [0.985238189603771], [0.9171832591837789], [0.8457221754695909], [1.588617215738164], [0.4899092580439613], [1.2518301173006279], [0.8524038440450842], [1.3356194358418028], [0.6052643902694366], [0.9838227516562361], [0.6940621509521361]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "942bd1c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surrogate</th>\n",
       "      <th>beta</th>\n",
       "      <th>inst_regret_test</th>\n",
       "      <th>inst_regret_pool</th>\n",
       "      <th>tot_regret_test</th>\n",
       "      <th>tot_regret_pool</th>\n",
       "      <th>calibration_mse</th>\n",
       "      <th>x_opt_dist_test</th>\n",
       "      <th>x_opt_dist_pool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BNN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.007725</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>2.125334</td>\n",
       "      <td>1.948328</td>\n",
       "      <td>0.082000</td>\n",
       "      <td>2.610578</td>\n",
       "      <td>1.465124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BNN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.016526</td>\n",
       "      <td>3.765185</td>\n",
       "      <td>3.588179</td>\n",
       "      <td>0.084382</td>\n",
       "      <td>2.482619</td>\n",
       "      <td>1.386001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BNN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020169</td>\n",
       "      <td>0.018417</td>\n",
       "      <td>4.204603</td>\n",
       "      <td>4.027596</td>\n",
       "      <td>0.087504</td>\n",
       "      <td>2.398777</td>\n",
       "      <td>1.964965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BNN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.041613</td>\n",
       "      <td>0.039861</td>\n",
       "      <td>4.933865</td>\n",
       "      <td>4.756858</td>\n",
       "      <td>0.087742</td>\n",
       "      <td>2.149339</td>\n",
       "      <td>2.489028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DE</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>1.232042</td>\n",
       "      <td>1.046420</td>\n",
       "      <td>0.025807</td>\n",
       "      <td>1.574652</td>\n",
       "      <td>0.583225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DE</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>1.101782</td>\n",
       "      <td>0.905631</td>\n",
       "      <td>0.019836</td>\n",
       "      <td>1.689658</td>\n",
       "      <td>0.154833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.017875</td>\n",
       "      <td>0.835843</td>\n",
       "      <td>0.022918</td>\n",
       "      <td>1.662880</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DE</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>1.186640</td>\n",
       "      <td>1.009634</td>\n",
       "      <td>0.019778</td>\n",
       "      <td>1.944907</td>\n",
       "      <td>0.616496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GP</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.005113</td>\n",
       "      <td>0.003360</td>\n",
       "      <td>1.925475</td>\n",
       "      <td>1.748468</td>\n",
       "      <td>0.023740</td>\n",
       "      <td>1.963147</td>\n",
       "      <td>1.582238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GP</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>1.660606</td>\n",
       "      <td>1.470916</td>\n",
       "      <td>0.022845</td>\n",
       "      <td>1.773306</td>\n",
       "      <td>1.007527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.523849</td>\n",
       "      <td>1.329612</td>\n",
       "      <td>0.019189</td>\n",
       "      <td>1.662880</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GP</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>1.567441</td>\n",
       "      <td>1.383973</td>\n",
       "      <td>0.016283</td>\n",
       "      <td>1.859725</td>\n",
       "      <td>0.761328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.005154</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>1.153447</td>\n",
       "      <td>0.969740</td>\n",
       "      <td>0.023909</td>\n",
       "      <td>1.852725</td>\n",
       "      <td>1.183552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>1.120655</td>\n",
       "      <td>0.943648</td>\n",
       "      <td>0.034261</td>\n",
       "      <td>1.815715</td>\n",
       "      <td>1.492772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RF</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004180</td>\n",
       "      <td>0.002428</td>\n",
       "      <td>0.956897</td>\n",
       "      <td>0.779891</td>\n",
       "      <td>0.027726</td>\n",
       "      <td>1.891897</td>\n",
       "      <td>0.738869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>1.142104</td>\n",
       "      <td>0.965098</td>\n",
       "      <td>0.014966</td>\n",
       "      <td>1.377074</td>\n",
       "      <td>1.104357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   surrogate  beta  inst_regret_test  inst_regret_pool  tot_regret_test  \\\n",
       "0        BNN   0.2          0.007725          0.005972         2.125334   \n",
       "1        BNN   0.5          0.018279          0.016526         3.765185   \n",
       "2        BNN   1.0          0.020169          0.018417         4.204603   \n",
       "3        BNN   2.0          0.041613          0.039861         4.933865   \n",
       "12        DE   0.2          0.004871          0.002879         1.232042   \n",
       "13        DE   0.5          0.002905          0.000913         1.101782   \n",
       "14        DE   1.0          0.001992          0.000000         1.017875   \n",
       "15        DE   2.0          0.002351          0.000598         1.186640   \n",
       "8         GP   0.2          0.005113          0.003360         1.925475   \n",
       "9         GP   0.5          0.003876          0.001884         1.660606   \n",
       "10        GP   1.0          0.001992          0.000000         1.523849   \n",
       "11        GP   2.0          0.002707          0.000715         1.567441   \n",
       "4         RF   0.2          0.005154          0.003162         1.153447   \n",
       "5         RF   0.5          0.004574          0.002821         1.120655   \n",
       "6         RF   1.0          0.004180          0.002428         0.956897   \n",
       "7         RF   2.0          0.005495          0.003742         1.142104   \n",
       "\n",
       "    tot_regret_pool  calibration_mse  x_opt_dist_test  x_opt_dist_pool  \n",
       "0          1.948328         0.082000         2.610578         1.465124  \n",
       "1          3.588179         0.084382         2.482619         1.386001  \n",
       "2          4.027596         0.087504         2.398777         1.964965  \n",
       "3          4.756858         0.087742         2.149339         2.489028  \n",
       "12         1.046420         0.025807         1.574652         0.583225  \n",
       "13         0.905631         0.019836         1.689658         0.154833  \n",
       "14         0.835843         0.022918         1.662880         0.000000  \n",
       "15         1.009634         0.019778         1.944907         0.616496  \n",
       "8          1.748468         0.023740         1.963147         1.582238  \n",
       "9          1.470916         0.022845         1.773306         1.007527  \n",
       "10         1.329612         0.019189         1.662880         0.000000  \n",
       "11         1.383973         0.016283         1.859725         0.761328  \n",
       "4          0.969740         0.023909         1.852725         1.183552  \n",
       "5          0.943648         0.034261         1.815715         1.492772  \n",
       "6          0.779891         0.027726         1.891897         0.738869  \n",
       "7          0.965098         0.014966         1.377074         1.104357  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "surrogates = ['BNN', 'RF', 'GP', 'DE']\n",
    "betas = [0.2, 0.5, 1, 2]\n",
    "exp_dict = {'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "results_dict = {surrogate:{beta:copy.deepcopy(exp_dict) for beta in betas} for surrogate in surrogates}\n",
    "directory=\"./results_mnist\"\n",
    "for foldername in os.listdir(directory):\n",
    "    folder = os.path.join(directory, foldername)\n",
    "    if os.path.isdir(folder):\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.find(\"parameters\") != -1:\n",
    "                json_file = open(os.path.join(folder, filename))\n",
    "                params = json.load(json_file)\n",
    "            elif filename.find(\"metrics\") != -1:\n",
    "                json_file = open(os.path.join(folder, filename))\n",
    "                metrics = json.load(json_file)\n",
    "        if params['bo'] == True and params['acquisition'] == \"UCB\":\n",
    "            #results_dict[params['surrogate']][params['beta'].append(params['beta'])\n",
    "            results_dict[params['surrogate']][params['beta']]['inst_regret_test'].append(metrics['y_regret_test'])\n",
    "            results_dict[params['surrogate']][params['beta']]['inst_regret_pool'].append(metrics['y_regret_pool'])\n",
    "            results_dict[params['surrogate']][params['beta']]['tot_regret_test'].append(np.cumsum(metrics['y_regret_test']))\n",
    "            results_dict[params['surrogate']][params['beta']]['tot_regret_pool'].append(np.cumsum(metrics['y_regret_pool']))\n",
    "            results_dict[params['surrogate']][params['beta']]['x_opt_dist_pool'].append(metrics['x_y_opt_dist_pool'])\n",
    "            results_dict[params['surrogate']][params['beta']]['x_opt_dist_test'].append(metrics['x_y_opt_dist_test'])\n",
    "            results_dict[params['surrogate']][params['beta']]['calibration_mse'].append(metrics['y_calibration_mse'])\n",
    "column_names = {'surrogate':[], 'beta':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for surrogate in surrogates:\n",
    "    for beta in betas:\n",
    "        result_dict = results_dict[surrogate][beta]\n",
    "        column_names['surrogate'].append(surrogate)\n",
    "        column_names['beta'].append(beta)\n",
    "        column_names['inst_regret_test'].append(np.array(result_dict['inst_regret_test']).mean(axis=0)[-1])\n",
    "        column_names['inst_regret_pool'].append(np.array(result_dict['inst_regret_pool']).mean(axis=0)[-1])\n",
    "        column_names['tot_regret_test'].append(np.array(result_dict['tot_regret_test']).mean(axis=0)[-1])\n",
    "        column_names['tot_regret_pool'].append(np.array(result_dict['tot_regret_pool']).mean(axis=0)[-1])\n",
    "        column_names['calibration_mse'].append(np.array(result_dict['calibration_mse']).mean(axis=0)[-1])\n",
    "        column_names['x_opt_dist_test'].append(np.array(result_dict['x_opt_dist_test']).mean(axis=0)[-1])\n",
    "        column_names['x_opt_dist_pool'].append(np.array(result_dict['x_opt_dist_pool']).mean(axis=0)[-1])    \n",
    "df = pd.DataFrame.from_dict(column_names)\n",
    "df = df.sort_values('surrogate')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c391cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acq</th>\n",
       "      <th>Surrogate</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCB</td>\n",
       "      <td>DE</td>\n",
       "      <td>2.733333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EI</td>\n",
       "      <td>DE</td>\n",
       "      <td>2.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCB</td>\n",
       "      <td>RF</td>\n",
       "      <td>2.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EI</td>\n",
       "      <td>RF</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCB</td>\n",
       "      <td>GP</td>\n",
       "      <td>4.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TS</td>\n",
       "      <td>GP</td>\n",
       "      <td>4.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EI</td>\n",
       "      <td>GP</td>\n",
       "      <td>5.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TS</td>\n",
       "      <td>DE</td>\n",
       "      <td>6.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RS</td>\n",
       "      <td>DE</td>\n",
       "      <td>8.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RS</td>\n",
       "      <td>RF</td>\n",
       "      <td>8.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TS</td>\n",
       "      <td>BNN</td>\n",
       "      <td>9.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RS</td>\n",
       "      <td>GP</td>\n",
       "      <td>9.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RS</td>\n",
       "      <td>BNN</td>\n",
       "      <td>9.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TS</td>\n",
       "      <td>RF</td>\n",
       "      <td>9.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCB</td>\n",
       "      <td>BNN</td>\n",
       "      <td>10.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EI</td>\n",
       "      <td>BNN</td>\n",
       "      <td>12.533333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Acq Surrogate       Rank\n",
       "1   UCB        DE   2.733333\n",
       "9    EI        DE   2.866667\n",
       "3   UCB        RF   2.966667\n",
       "11   EI        RF   3.000000\n",
       "2   UCB        GP   4.633333\n",
       "6    TS        GP   4.900000\n",
       "10   EI        GP   5.133333\n",
       "5    TS        DE   6.633333\n",
       "13   RS        DE   8.033333\n",
       "15   RS        RF   8.933333\n",
       "4    TS       BNN   9.033333\n",
       "14   RS        GP   9.466667\n",
       "12   RS       BNN   9.533333\n",
       "7    TS        RF   9.600000\n",
       "0   UCB       BNN  10.600000\n",
       "8    EI       BNN  12.533333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Instantaneous regret of pool rankings from real_data with recalibrated uncertanties.\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "exp_dict = {'surrogate': [], 'acquisition': [], 'seed':[], 'data':[], 'dist_nearest_train':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "main_directory=\"./results_real_data/\"\n",
    "subdirectories = ['results_FashionMNIST_recalibrator/', \"results_FashionMNIST_CNN_recalibrator/\", 'results_mnist_recalibrator/', 'results_MNIST_CNN_recalibrator/', 'results_News_recalibrator/', 'results_SVM_recalibrator/']\n",
    "for subdirectory in subdirectories:\n",
    "    full_path = os.path.join(main_directory, subdirectory)\n",
    "    for foldername in os.listdir(full_path):\n",
    "        folder = os.path.join(full_path, foldername)\n",
    "        if os.path.isdir(folder):\n",
    "            for filename in os.listdir(folder):\n",
    "                if filename.find(\"parameters\") != -1:\n",
    "                    json_file = open(os.path.join(folder, filename))\n",
    "                    params = json.load(json_file)\n",
    "                elif filename.find(\"metrics\") != -1:\n",
    "                    json_file = open(os.path.join(folder, filename))\n",
    "                    metrics = json.load(json_file)\n",
    "            if params['bo'] == True:\n",
    "                exp_dict['surrogate'].append(params['surrogate'])\n",
    "                exp_dict['acquisition'].append(params['acquisition'])\n",
    "                exp_dict['data'].append(params['data_name'])\n",
    "                exp_dict['dist_nearest_train'].append(metrics['next_sample_train_distance'])\n",
    "                exp_dict['inst_regret_test'].append(metrics['y_regret_test'])\n",
    "                exp_dict['inst_regret_pool'].append(metrics['y_regret_pool'])\n",
    "                exp_dict['tot_regret_test'].append(np.cumsum(metrics['y_regret_test']))\n",
    "                exp_dict['tot_regret_pool'].append(np.cumsum(metrics['y_regret_pool']))\n",
    "                exp_dict['x_opt_dist_pool'].append(metrics['x_y_opt_dist_pool'])\n",
    "                exp_dict['x_opt_dist_test'].append(metrics['x_y_opt_dist_test'])\n",
    "                exp_dict['sharpness'].append(metrics['mean_sharpness'])\n",
    "                exp_dict['calibration_mse'].append(metrics['y_calibration_mse'])\n",
    "                exp_dict['seed'].append(params['seed'])\n",
    "df = pd.DataFrame.from_dict(exp_dict)\n",
    "processed_results = {'surrogate': [], 'acquisition': [], 'seed':[], 'data':[], 'dist_nearest_train_mean':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for index, row in df.iterrows():\n",
    "    processed_results['surrogate'].append(row['surrogate'])\n",
    "    processed_results['acquisition'].append(row['acquisition'])\n",
    "    processed_results['data'].append(row['data'])\n",
    "    processed_results['seed'].append(row['seed'])\n",
    "    processed_results['dist_nearest_train_mean'].append(np.array(row['dist_nearest_train']).mean()) #Mean across one BO run.\n",
    "    processed_results['inst_regret_pool'].append(np.array(row['inst_regret_pool'])[-1]) #Last iter.\n",
    "    processed_results['inst_regret_test'].append(np.array(row['inst_regret_test'])[-1]) #Last iter.\n",
    "    processed_results['tot_regret_test'].append(np.array(row['tot_regret_test'])[-1]) #Last iter.\n",
    "    processed_results['tot_regret_pool'].append(np.array(row['tot_regret_pool'])[-1]) #Last iter.\n",
    "    processed_results['calibration_mse'].append(np.array(row['calibration_mse']).mean()) #Mean Calibration MSE over run.\n",
    "    processed_results['sharpness'].append(np.array(row['sharpness']).mean()) #Mean sharpness over run.\n",
    "    processed_results['x_opt_dist_test'].append(np.array(row['x_opt_dist_test'])[-1])\n",
    "    processed_results['x_opt_dist_pool'].append(np.array(row['x_opt_dist_pool'])[-1])\n",
    "#Same seed and same dataset are ranked together.\n",
    "df = pd.DataFrame.from_dict(processed_results)\n",
    "seeds = np.arange(5)+1\n",
    "datasets = ['fashionmnist', 'fashionmnist_cnn', 'mnist', 'mnist_cnn', 'news', 'svm_wine']\n",
    "for seed in seeds:\n",
    "    for dataset in datasets:\n",
    "        #For one problem and one seed, we get a ranking going from 1-16 (depending on ties) since there are 4 surrogates and 4 acqs.\n",
    "        selection = df.loc[(df['data']==dataset) & (df['seed']==seed)]\n",
    "        df.loc[((df['data']==dataset) & (df['seed']==seed)),'min_rank'] = selection['inst_regret_pool'].rank(method=\"min\")\n",
    "acqs = ['UCB', 'TS', 'EI', 'RS']\n",
    "surrogates = ['BNN', 'DE', 'GP', 'RF']\n",
    "ranking_dict  = {'Acq':[], 'Surrogate':[], 'Rank':[]}\n",
    "for acq in acqs:\n",
    "    for surrogate in surrogates:\n",
    "        ranking_dict['Rank'].append(df.loc[((df['acquisition']==acq) & (df['surrogate']==surrogate)),'min_rank'].mean())\n",
    "        ranking_dict['Acq'].append(acq)\n",
    "        ranking_dict['Surrogate'].append(surrogate)\n",
    "display(pd.DataFrame.from_dict(ranking_dict).sort_values('Rank'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0979e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acq</th>\n",
       "      <th>Surrogate</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UCB</td>\n",
       "      <td>DE</td>\n",
       "      <td>2.205387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EI</td>\n",
       "      <td>DE</td>\n",
       "      <td>2.260943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TS</td>\n",
       "      <td>DE</td>\n",
       "      <td>2.735690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TS</td>\n",
       "      <td>RF</td>\n",
       "      <td>2.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UCB</td>\n",
       "      <td>GP</td>\n",
       "      <td>4.013468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>EI</td>\n",
       "      <td>GP</td>\n",
       "      <td>4.451178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>EI</td>\n",
       "      <td>RF</td>\n",
       "      <td>5.419192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCB</td>\n",
       "      <td>RF</td>\n",
       "      <td>5.484848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TS</td>\n",
       "      <td>GP</td>\n",
       "      <td>5.747475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UCB</td>\n",
       "      <td>BNN</td>\n",
       "      <td>7.740741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RS</td>\n",
       "      <td>DE</td>\n",
       "      <td>9.897306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RS</td>\n",
       "      <td>BNN</td>\n",
       "      <td>9.898990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RS</td>\n",
       "      <td>RF</td>\n",
       "      <td>9.951178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RS</td>\n",
       "      <td>GP</td>\n",
       "      <td>9.991582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TS</td>\n",
       "      <td>BNN</td>\n",
       "      <td>10.069024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EI</td>\n",
       "      <td>BNN</td>\n",
       "      <td>11.109428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Acq Surrogate       Rank\n",
       "1   UCB        DE   2.205387\n",
       "9    EI        DE   2.260943\n",
       "5    TS        DE   2.735690\n",
       "7    TS        RF   2.863636\n",
       "2   UCB        GP   4.013468\n",
       "10   EI        GP   4.451178\n",
       "11   EI        RF   5.419192\n",
       "3   UCB        RF   5.484848\n",
       "6    TS        GP   5.747475\n",
       "0   UCB       BNN   7.740741\n",
       "13   RS        DE   9.897306\n",
       "12   RS       BNN   9.898990\n",
       "15   RS        RF   9.951178\n",
       "14   RS        GP   9.991582\n",
       "4    TS       BNN  10.069024\n",
       "8    EI       BNN  11.109428"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Instantaneous regret of pool rankings from real_data with vanilla uncertanties.\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "exp_dict = {'surrogate': [], 'acquisition': [], 'seed':[], 'data':[], 'dist_nearest_train':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "main_directory=\"./results_real_data/\"\n",
    "subdirectories = ['results_FashionMNIST/', \"results_FashionMNIST_CNN/\", 'results_mnist/', 'results_MNIST_CNN/', 'results_News/', 'results_SVM/']\n",
    "for subdirectory in subdirectories:\n",
    "    full_path = os.path.join(main_directory, subdirectory)\n",
    "    for foldername in os.listdir(full_path):\n",
    "        folder = os.path.join(full_path, foldername)\n",
    "        if os.path.isdir(folder):\n",
    "            for filename in os.listdir(folder):\n",
    "                if filename.find(\"parameters\") != -1:\n",
    "                    json_file = open(os.path.join(folder, filename))\n",
    "                    params = json.load(json_file)\n",
    "                elif filename.find(\"metrics\") != -1:\n",
    "                    json_file = open(os.path.join(folder, filename))\n",
    "                    metrics = json.load(json_file)\n",
    "            if params['bo'] == True:\n",
    "                exp_dict['surrogate'].append(params['surrogate'])\n",
    "                exp_dict['acquisition'].append(params['acquisition'])\n",
    "                exp_dict['data'].append(params['data_name'])\n",
    "                exp_dict['dist_nearest_train'].append(metrics['next_sample_train_distance'])\n",
    "                exp_dict['inst_regret_test'].append(metrics['y_regret_test'])\n",
    "                exp_dict['inst_regret_pool'].append(metrics['y_regret_pool'])\n",
    "                exp_dict['tot_regret_test'].append(np.cumsum(metrics['y_regret_test']))\n",
    "                exp_dict['tot_regret_pool'].append(np.cumsum(metrics['y_regret_pool']))\n",
    "                exp_dict['x_opt_dist_pool'].append(metrics['x_y_opt_dist_pool'])\n",
    "                exp_dict['x_opt_dist_test'].append(metrics['x_y_opt_dist_test'])\n",
    "                exp_dict['sharpness'].append(metrics['mean_sharpness'])\n",
    "                exp_dict['calibration_mse'].append(metrics['y_calibration_mse'])\n",
    "                exp_dict['seed'].append(params['seed'])\n",
    "df = pd.DataFrame.from_dict(exp_dict)\n",
    "processed_results = {'surrogate': [], 'acquisition': [], 'seed':[], 'data':[], 'dist_nearest_train_mean':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for index, row in df.iterrows():\n",
    "    processed_results['surrogate'].append(row['surrogate'])\n",
    "    processed_results['acquisition'].append(row['acquisition'])\n",
    "    processed_results['data'].append(row['data'])\n",
    "    processed_results['seed'].append(row['seed'])\n",
    "    processed_results['dist_nearest_train_mean'].append(np.array(row['dist_nearest_train']).mean()) #Mean across one BO run.\n",
    "    processed_results['inst_regret_pool'].append(np.array(row['inst_regret_pool'])[-1]) #Last iter.\n",
    "    processed_results['inst_regret_test'].append(np.array(row['inst_regret_test'])[-1]) #Last iter.\n",
    "    processed_results['tot_regret_test'].append(np.array(row['tot_regret_test'])[-1]) #Last iter.\n",
    "    processed_results['tot_regret_pool'].append(np.array(row['tot_regret_pool'])[-1]) #Last iter.\n",
    "    processed_results['calibration_mse'].append(np.array(row['calibration_mse']).mean()) #Mean Calibration MSE over run.\n",
    "    processed_results['sharpness'].append(np.array(row['sharpness']).mean()) #Mean sharpness over run.\n",
    "    processed_results['x_opt_dist_test'].append(np.array(row['x_opt_dist_test'])[-1])\n",
    "    processed_results['x_opt_dist_pool'].append(np.array(row['x_opt_dist_pool'])[-1])\n",
    "#Same seed and same dataset are ranked together.\n",
    "df = pd.DataFrame.from_dict(processed_results)\n",
    "seeds = np.arange(99)+1\n",
    "datasets = ['fashionmnist', 'fashionmnist_cnn', 'mnist', 'mnist_cnn', 'news', 'svm_wine']\n",
    "for seed in seeds:\n",
    "    for dataset in datasets:\n",
    "        #For one problem and one seed, we get a ranking going from 1-16 (depending on ties) since there are 4 surrogates and 4 acqs.\n",
    "        selection = df.loc[(df['data']==dataset) & (df['seed']==seed)]\n",
    "        df.loc[((df['data']==dataset) & (df['seed']==seed)),'min_rank'] = selection['inst_regret_pool'].rank(method=\"min\")\n",
    "acqs = ['UCB', 'TS', 'EI', 'RS']\n",
    "surrogates = ['BNN', 'DE', 'GP', 'RF']\n",
    "ranking_dict  = {'Acq':[], 'Surrogate':[], 'Rank':[]}\n",
    "for acq in acqs:\n",
    "    for surrogate in surrogates:\n",
    "        ranking_dict['Rank'].append(df.loc[((df['acquisition']==acq) & (df['surrogate']==surrogate)),'min_rank'].mean())\n",
    "        ranking_dict['Acq'].append(acq)\n",
    "        ranking_dict['Surrogate'].append(surrogate)\n",
    "display(pd.DataFrame.from_dict(ranking_dict).sort_values('Rank'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23352242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surrogate</th>\n",
       "      <th>acquisition</th>\n",
       "      <th>dist_nearest_train_mean</th>\n",
       "      <th>inst_regret_test</th>\n",
       "      <th>inst_regret_pool</th>\n",
       "      <th>tot_regret_test</th>\n",
       "      <th>tot_regret_pool</th>\n",
       "      <th>calibration_mse</th>\n",
       "      <th>sharpness</th>\n",
       "      <th>x_opt_dist_test</th>\n",
       "      <th>x_opt_dist_pool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DE</td>\n",
       "      <td>EI</td>\n",
       "      <td>0.735608</td>\n",
       "      <td>0.003510</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>1.069865</td>\n",
       "      <td>0.907612</td>\n",
       "      <td>0.036479</td>\n",
       "      <td>-0.292877</td>\n",
       "      <td>1.773260</td>\n",
       "      <td>0.964370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.746360</td>\n",
       "      <td>0.003547</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>1.080744</td>\n",
       "      <td>0.918378</td>\n",
       "      <td>0.037014</td>\n",
       "      <td>-0.286789</td>\n",
       "      <td>1.774084</td>\n",
       "      <td>0.916126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DE</td>\n",
       "      <td>TS</td>\n",
       "      <td>0.831609</td>\n",
       "      <td>0.003803</td>\n",
       "      <td>0.001632</td>\n",
       "      <td>1.189891</td>\n",
       "      <td>1.037580</td>\n",
       "      <td>0.036536</td>\n",
       "      <td>-0.252596</td>\n",
       "      <td>1.781125</td>\n",
       "      <td>1.075754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF</td>\n",
       "      <td>TS</td>\n",
       "      <td>0.902959</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>1.436355</td>\n",
       "      <td>1.321771</td>\n",
       "      <td>0.010140</td>\n",
       "      <td>0.888867</td>\n",
       "      <td>1.754771</td>\n",
       "      <td>1.009665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.858249</td>\n",
       "      <td>0.004445</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>1.628855</td>\n",
       "      <td>1.524514</td>\n",
       "      <td>0.014904</td>\n",
       "      <td>-0.529606</td>\n",
       "      <td>1.789162</td>\n",
       "      <td>1.284411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GP</td>\n",
       "      <td>EI</td>\n",
       "      <td>0.924548</td>\n",
       "      <td>0.004786</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>1.646233</td>\n",
       "      <td>1.545796</td>\n",
       "      <td>0.015263</td>\n",
       "      <td>-0.545129</td>\n",
       "      <td>1.783500</td>\n",
       "      <td>1.367458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.862667</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.004243</td>\n",
       "      <td>1.194338</td>\n",
       "      <td>1.100580</td>\n",
       "      <td>0.015616</td>\n",
       "      <td>0.923084</td>\n",
       "      <td>1.848321</td>\n",
       "      <td>1.547104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>EI</td>\n",
       "      <td>0.866540</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>1.192190</td>\n",
       "      <td>1.095306</td>\n",
       "      <td>0.014568</td>\n",
       "      <td>0.873947</td>\n",
       "      <td>1.784204</td>\n",
       "      <td>1.533454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GP</td>\n",
       "      <td>TS</td>\n",
       "      <td>0.936842</td>\n",
       "      <td>0.005937</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>1.841756</td>\n",
       "      <td>1.759365</td>\n",
       "      <td>0.012485</td>\n",
       "      <td>-0.582317</td>\n",
       "      <td>1.780415</td>\n",
       "      <td>1.523541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BNN</td>\n",
       "      <td>UCB</td>\n",
       "      <td>1.022831</td>\n",
       "      <td>0.011812</td>\n",
       "      <td>0.010389</td>\n",
       "      <td>2.743519</td>\n",
       "      <td>2.637321</td>\n",
       "      <td>0.101380</td>\n",
       "      <td>1.045786</td>\n",
       "      <td>1.920689</td>\n",
       "      <td>1.764657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BNN</td>\n",
       "      <td>RS</td>\n",
       "      <td>1.047915</td>\n",
       "      <td>0.015561</td>\n",
       "      <td>0.015020</td>\n",
       "      <td>2.656071</td>\n",
       "      <td>2.603124</td>\n",
       "      <td>0.101542</td>\n",
       "      <td>1.349843</td>\n",
       "      <td>1.904635</td>\n",
       "      <td>1.848783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GP</td>\n",
       "      <td>RS</td>\n",
       "      <td>1.049375</td>\n",
       "      <td>0.015677</td>\n",
       "      <td>0.015138</td>\n",
       "      <td>2.765933</td>\n",
       "      <td>2.713823</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>-0.776042</td>\n",
       "      <td>1.867386</td>\n",
       "      <td>1.925308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RF</td>\n",
       "      <td>RS</td>\n",
       "      <td>1.049819</td>\n",
       "      <td>0.015840</td>\n",
       "      <td>0.015217</td>\n",
       "      <td>2.763430</td>\n",
       "      <td>2.707615</td>\n",
       "      <td>0.007238</td>\n",
       "      <td>1.030790</td>\n",
       "      <td>1.886164</td>\n",
       "      <td>1.898263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DE</td>\n",
       "      <td>RS</td>\n",
       "      <td>1.050825</td>\n",
       "      <td>0.016672</td>\n",
       "      <td>0.016135</td>\n",
       "      <td>2.847324</td>\n",
       "      <td>2.796052</td>\n",
       "      <td>0.009274</td>\n",
       "      <td>-0.257804</td>\n",
       "      <td>1.934120</td>\n",
       "      <td>1.900433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BNN</td>\n",
       "      <td>TS</td>\n",
       "      <td>1.103216</td>\n",
       "      <td>0.018273</td>\n",
       "      <td>0.017682</td>\n",
       "      <td>3.062469</td>\n",
       "      <td>3.006914</td>\n",
       "      <td>0.102468</td>\n",
       "      <td>1.063956</td>\n",
       "      <td>2.006490</td>\n",
       "      <td>1.959261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>1.029453</td>\n",
       "      <td>0.034142</td>\n",
       "      <td>0.033408</td>\n",
       "      <td>4.931788</td>\n",
       "      <td>4.870896</td>\n",
       "      <td>0.105199</td>\n",
       "      <td>0.792186</td>\n",
       "      <td>2.215759</td>\n",
       "      <td>2.106140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   surrogate acquisition  dist_nearest_train_mean  inst_regret_test  \\\n",
       "9         DE          EI                 0.735608          0.003510   \n",
       "1         DE         UCB                 0.746360          0.003547   \n",
       "5         DE          TS                 0.831609          0.003803   \n",
       "7         RF          TS                 0.902959          0.003797   \n",
       "2         GP         UCB                 0.858249          0.004445   \n",
       "10        GP          EI                 0.924548          0.004786   \n",
       "3         RF         UCB                 0.862667          0.005356   \n",
       "11        RF          EI                 0.866540          0.005461   \n",
       "6         GP          TS                 0.936842          0.005937   \n",
       "0        BNN         UCB                 1.022831          0.011812   \n",
       "12       BNN          RS                 1.047915          0.015561   \n",
       "14        GP          RS                 1.049375          0.015677   \n",
       "15        RF          RS                 1.049819          0.015840   \n",
       "13        DE          RS                 1.050825          0.016672   \n",
       "4        BNN          TS                 1.103216          0.018273   \n",
       "8        BNN          EI                 1.029453          0.034142   \n",
       "\n",
       "    inst_regret_pool  tot_regret_test  tot_regret_pool  calibration_mse  \\\n",
       "9           0.001147         1.069865         0.907612         0.036479   \n",
       "1           0.001220         1.080744         0.918378         0.037014   \n",
       "5           0.001632         1.189891         1.037580         0.036536   \n",
       "7           0.001741         1.436355         1.321771         0.010140   \n",
       "2           0.002641         1.628855         1.524514         0.014904   \n",
       "10          0.003076         1.646233         1.545796         0.015263   \n",
       "3           0.004243         1.194338         1.100580         0.015616   \n",
       "11          0.004269         1.192190         1.095306         0.014568   \n",
       "6           0.004578         1.841756         1.759365         0.012485   \n",
       "0           0.010389         2.743519         2.637321         0.101380   \n",
       "12          0.015020         2.656071         2.603124         0.101542   \n",
       "14          0.015138         2.765933         2.713823         0.005511   \n",
       "15          0.015217         2.763430         2.707615         0.007238   \n",
       "13          0.016135         2.847324         2.796052         0.009274   \n",
       "4           0.017682         3.062469         3.006914         0.102468   \n",
       "8           0.033408         4.931788         4.870896         0.105199   \n",
       "\n",
       "    sharpness  x_opt_dist_test  x_opt_dist_pool  \n",
       "9   -0.292877         1.773260         0.964370  \n",
       "1   -0.286789         1.774084         0.916126  \n",
       "5   -0.252596         1.781125         1.075754  \n",
       "7    0.888867         1.754771         1.009665  \n",
       "2   -0.529606         1.789162         1.284411  \n",
       "10  -0.545129         1.783500         1.367458  \n",
       "3    0.923084         1.848321         1.547104  \n",
       "11   0.873947         1.784204         1.533454  \n",
       "6   -0.582317         1.780415         1.523541  \n",
       "0    1.045786         1.920689         1.764657  \n",
       "12   1.349843         1.904635         1.848783  \n",
       "14  -0.776042         1.867386         1.925308  \n",
       "15   1.030790         1.886164         1.898263  \n",
       "13  -0.257804         1.934120         1.900433  \n",
       "4    1.063956         2.006490         1.959261  \n",
       "8    0.792186         2.215759         2.106140  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surrogate</th>\n",
       "      <th>acquisition</th>\n",
       "      <th>dist_nearest_train_mean</th>\n",
       "      <th>inst_regret_test</th>\n",
       "      <th>inst_regret_pool</th>\n",
       "      <th>tot_regret_test</th>\n",
       "      <th>tot_regret_pool</th>\n",
       "      <th>calibration_mse</th>\n",
       "      <th>sharpness</th>\n",
       "      <th>x_opt_dist_test</th>\n",
       "      <th>x_opt_dist_pool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DE</td>\n",
       "      <td>EI</td>\n",
       "      <td>0.019069</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.115486</td>\n",
       "      <td>0.107678</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>0.023710</td>\n",
       "      <td>0.098480</td>\n",
       "      <td>0.123392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.019246</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.115019</td>\n",
       "      <td>0.107633</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.024001</td>\n",
       "      <td>0.096486</td>\n",
       "      <td>0.118929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DE</td>\n",
       "      <td>TS</td>\n",
       "      <td>0.022101</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.126511</td>\n",
       "      <td>0.120780</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>0.024523</td>\n",
       "      <td>0.097967</td>\n",
       "      <td>0.123117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF</td>\n",
       "      <td>TS</td>\n",
       "      <td>0.028439</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.127867</td>\n",
       "      <td>0.122707</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.211595</td>\n",
       "      <td>0.092501</td>\n",
       "      <td>0.116124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.029518</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000487</td>\n",
       "      <td>0.143703</td>\n",
       "      <td>0.138067</td>\n",
       "      <td>0.000987</td>\n",
       "      <td>0.037861</td>\n",
       "      <td>0.092997</td>\n",
       "      <td>0.119322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GP</td>\n",
       "      <td>EI</td>\n",
       "      <td>0.031227</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.145160</td>\n",
       "      <td>0.139343</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>0.037538</td>\n",
       "      <td>0.094036</td>\n",
       "      <td>0.115111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.031649</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.117398</td>\n",
       "      <td>0.112382</td>\n",
       "      <td>0.000960</td>\n",
       "      <td>0.192322</td>\n",
       "      <td>0.094563</td>\n",
       "      <td>0.108752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>EI</td>\n",
       "      <td>0.031932</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.119542</td>\n",
       "      <td>0.113402</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>0.091577</td>\n",
       "      <td>0.111549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GP</td>\n",
       "      <td>TS</td>\n",
       "      <td>0.023768</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.163155</td>\n",
       "      <td>0.158650</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.042659</td>\n",
       "      <td>0.091926</td>\n",
       "      <td>0.106616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GP</td>\n",
       "      <td>RS</td>\n",
       "      <td>0.039103</td>\n",
       "      <td>0.001566</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.247266</td>\n",
       "      <td>0.245474</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.034217</td>\n",
       "      <td>0.089973</td>\n",
       "      <td>0.087768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RF</td>\n",
       "      <td>RS</td>\n",
       "      <td>0.039236</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.256501</td>\n",
       "      <td>0.251384</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.250727</td>\n",
       "      <td>0.090633</td>\n",
       "      <td>0.091586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BNN</td>\n",
       "      <td>RS</td>\n",
       "      <td>0.039147</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.235823</td>\n",
       "      <td>0.232579</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.025119</td>\n",
       "      <td>0.089690</td>\n",
       "      <td>0.092150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BNN</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.038271</td>\n",
       "      <td>0.001718</td>\n",
       "      <td>0.001685</td>\n",
       "      <td>0.297382</td>\n",
       "      <td>0.290151</td>\n",
       "      <td>0.001440</td>\n",
       "      <td>0.021645</td>\n",
       "      <td>0.105853</td>\n",
       "      <td>0.114945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DE</td>\n",
       "      <td>RS</td>\n",
       "      <td>0.039204</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.256662</td>\n",
       "      <td>0.254701</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.032951</td>\n",
       "      <td>0.092671</td>\n",
       "      <td>0.093168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BNN</td>\n",
       "      <td>TS</td>\n",
       "      <td>0.036056</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.304436</td>\n",
       "      <td>0.303887</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.022382</td>\n",
       "      <td>0.095409</td>\n",
       "      <td>0.096980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>0.036433</td>\n",
       "      <td>0.004394</td>\n",
       "      <td>0.004391</td>\n",
       "      <td>0.554290</td>\n",
       "      <td>0.552978</td>\n",
       "      <td>0.001614</td>\n",
       "      <td>0.033574</td>\n",
       "      <td>0.103163</td>\n",
       "      <td>0.106918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   surrogate acquisition  dist_nearest_train_mean  inst_regret_test  \\\n",
       "9         DE          EI                 0.019069          0.000443   \n",
       "1         DE         UCB                 0.019246          0.000446   \n",
       "5         DE          TS                 0.022101          0.000475   \n",
       "7         RF          TS                 0.028439          0.000486   \n",
       "2         GP         UCB                 0.029518          0.000568   \n",
       "10        GP          EI                 0.031227          0.000572   \n",
       "3         RF         UCB                 0.031649          0.000658   \n",
       "11        RF          EI                 0.031932          0.000681   \n",
       "6         GP          TS                 0.023768          0.000700   \n",
       "14        GP          RS                 0.039103          0.001566   \n",
       "15        RF          RS                 0.039236          0.001707   \n",
       "12       BNN          RS                 0.039147          0.001690   \n",
       "0        BNN         UCB                 0.038271          0.001718   \n",
       "13        DE          RS                 0.039204          0.001800   \n",
       "4        BNN          TS                 0.036056          0.002099   \n",
       "8        BNN          EI                 0.036433          0.004394   \n",
       "\n",
       "    inst_regret_pool  tot_regret_test  tot_regret_pool  calibration_mse  \\\n",
       "9           0.000300         0.115486         0.107678         0.002358   \n",
       "1           0.000339         0.115019         0.107633         0.002297   \n",
       "5           0.000378         0.126511         0.120780         0.002301   \n",
       "7           0.000394         0.127867         0.122707         0.000600   \n",
       "2           0.000487         0.143703         0.138067         0.000987   \n",
       "10          0.000533         0.145160         0.139343         0.001031   \n",
       "3           0.000615         0.117398         0.112382         0.000960   \n",
       "11          0.000632         0.119542         0.113402         0.000889   \n",
       "6           0.000665         0.163155         0.158650         0.000849   \n",
       "14          0.001546         0.247266         0.245474         0.000265   \n",
       "15          0.001653         0.256501         0.251384         0.000409   \n",
       "12          0.001661         0.235823         0.232579         0.001126   \n",
       "0           0.001685         0.297382         0.290151         0.001440   \n",
       "13          0.001780         0.256662         0.254701         0.000308   \n",
       "4           0.002102         0.304436         0.303887         0.001321   \n",
       "8           0.004391         0.554290         0.552978         0.001614   \n",
       "\n",
       "    sharpness  x_opt_dist_test  x_opt_dist_pool  \n",
       "9    0.023710         0.098480         0.123392  \n",
       "1    0.024001         0.096486         0.118929  \n",
       "5    0.024523         0.097967         0.123117  \n",
       "7    0.211595         0.092501         0.116124  \n",
       "2    0.037861         0.092997         0.119322  \n",
       "10   0.037538         0.094036         0.115111  \n",
       "3    0.192322         0.094563         0.108752  \n",
       "11   0.188000         0.091577         0.111549  \n",
       "6    0.042659         0.091926         0.106616  \n",
       "14   0.034217         0.089973         0.087768  \n",
       "15   0.250727         0.090633         0.091586  \n",
       "12   0.025119         0.089690         0.092150  \n",
       "0    0.021645         0.105853         0.114945  \n",
       "13   0.032951         0.092671         0.093168  \n",
       "4    0.022382         0.095409         0.096980  \n",
       "8    0.033574         0.103163         0.106918  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Metrics at final iteration of real_data experiment with standard error of the mean reported in separate DataFrame.\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "exp_dict = {'surrogate': [], 'acquisition': [], 'seed':[], 'data':[], 'dist_nearest_train':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "main_directory=\"./results_real_data/\"\n",
    "subdirectories = ['results_FashionMNIST/', \"results_FashionMNIST_CNN/\", 'results_mnist/', 'results_MNIST_CNN/', 'results_News/', 'results_SVM/']\n",
    "for subdirectory in subdirectories:\n",
    "    full_path = os.path.join(main_directory, subdirectory)\n",
    "    for foldername in os.listdir(full_path):\n",
    "        folder = os.path.join(full_path, foldername)\n",
    "        if os.path.isdir(folder):\n",
    "            for filename in os.listdir(folder):\n",
    "                if filename.find(\"parameters\") != -1:\n",
    "                    json_file = open(os.path.join(folder, filename))\n",
    "                    params = json.load(json_file)\n",
    "                elif filename.find(\"metrics\") != -1:\n",
    "                    json_file = open(os.path.join(folder, filename))\n",
    "                    metrics = json.load(json_file)\n",
    "            if params['bo'] == True:\n",
    "                exp_dict['surrogate'].append(params['surrogate'])\n",
    "                exp_dict['acquisition'].append(params['acquisition'])\n",
    "                exp_dict['data'].append(params['data_name'])\n",
    "                exp_dict['dist_nearest_train'].append(metrics['next_sample_train_distance'])\n",
    "                exp_dict['inst_regret_test'].append(metrics['y_regret_test'])\n",
    "                exp_dict['inst_regret_pool'].append(metrics['y_regret_pool'])\n",
    "                exp_dict['tot_regret_test'].append(np.cumsum(metrics['y_regret_test']))\n",
    "                exp_dict['tot_regret_pool'].append(np.cumsum(metrics['y_regret_pool']))\n",
    "                exp_dict['x_opt_dist_pool'].append(metrics['x_y_opt_dist_pool'])\n",
    "                exp_dict['x_opt_dist_test'].append(metrics['x_y_opt_dist_test'])\n",
    "                exp_dict['sharpness'].append(metrics['mean_sharpness'])\n",
    "                exp_dict['calibration_mse'].append(metrics['y_calibration_mse'])\n",
    "                exp_dict['seed'].append(params['seed'])\n",
    "df = pd.DataFrame.from_dict(exp_dict)\n",
    "processed_results = {'surrogate': [], 'acquisition': [], 'seed':[], 'data':[], 'dist_nearest_train_mean':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for index, row in df.iterrows():\n",
    "    processed_results['surrogate'].append(row['surrogate'])\n",
    "    processed_results['acquisition'].append(row['acquisition'])\n",
    "    processed_results['data'].append(row['data'])\n",
    "    processed_results['seed'].append(row['seed'])\n",
    "    processed_results['dist_nearest_train_mean'].append(np.array(row['dist_nearest_train']).mean()) #Mean across one BO run.\n",
    "    processed_results['inst_regret_pool'].append(np.array(row['inst_regret_pool'])[-1]) #Last iter.\n",
    "    processed_results['inst_regret_test'].append(np.array(row['inst_regret_test'])[-1]) #Last iter.\n",
    "    processed_results['tot_regret_test'].append(np.array(row['tot_regret_test'])[-1]) #Last iter.\n",
    "    processed_results['tot_regret_pool'].append(np.array(row['tot_regret_pool'])[-1]) #Last iter.\n",
    "    processed_results['calibration_mse'].append(np.array(row['calibration_mse']).mean(axis=0)) #Mean Calibration MSE over run.\n",
    "    processed_results['sharpness'].append(np.array(row['sharpness']).mean()) #Mean sharpness over run.\n",
    "    processed_results['x_opt_dist_test'].append(np.array(row['x_opt_dist_test'])[-1])\n",
    "    processed_results['x_opt_dist_pool'].append(np.array(row['x_opt_dist_pool'])[-1])\n",
    "df = pd.DataFrame.from_dict(processed_results)\n",
    "acqs = ['UCB', 'TS', 'EI', 'RS']\n",
    "surrogates = ['BNN', 'DE', 'GP', 'RF']\n",
    "seeds = 99\n",
    "aggregated_processed_results = {'surrogate': [], 'acquisition': [], 'dist_nearest_train_mean':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for acq in acqs:\n",
    "    for surrogate in surrogates:\n",
    "        selection = df.loc[((df['acquisition']==acq) & (df['surrogate']==surrogate))]\n",
    "        aggregated_processed_results['surrogate'].append(surrogate)\n",
    "        aggregated_processed_results['acquisition'].append(acq)\n",
    "        aggregated_processed_results['dist_nearest_train_mean'].append(np.mean(selection['dist_nearest_train_mean']))\n",
    "        aggregated_processed_results['inst_regret_test'].append(np.mean(selection['inst_regret_test']))\n",
    "        aggregated_processed_results['inst_regret_pool'].append(np.mean(selection['inst_regret_pool']))\n",
    "        aggregated_processed_results['tot_regret_test'].append(np.mean(selection['tot_regret_test']))\n",
    "        aggregated_processed_results['tot_regret_pool'].append(np.mean(selection['tot_regret_pool']))\n",
    "        aggregated_processed_results['calibration_mse'].append(np.mean(selection['calibration_mse']))\n",
    "        aggregated_processed_results['sharpness'].append(np.mean(selection['sharpness']))\n",
    "        aggregated_processed_results['x_opt_dist_test'].append(np.mean(selection['x_opt_dist_test']))\n",
    "        aggregated_processed_results['x_opt_dist_pool'].append(np.mean(selection['x_opt_dist_pool']))\n",
    "df2 = pd.DataFrame.from_dict(aggregated_processed_results)\n",
    "df2 = df2.sort_values('inst_regret_pool')\n",
    "display(df2)\n",
    "acqs = ['UCB', 'TS', 'EI', 'RS']\n",
    "surrogates = ['BNN', 'DE', 'GP', 'RF']\n",
    "aggregated_processed_results_std = {'surrogate': [], 'acquisition': [], 'dist_nearest_train_mean':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for acq in acqs:\n",
    "    for surrogate in surrogates:\n",
    "        selection = df.loc[((df['acquisition']==acq) & (df['surrogate']==surrogate))]\n",
    "        aggregated_processed_results_std['surrogate'].append(surrogate)\n",
    "        aggregated_processed_results_std['acquisition'].append(acq)\n",
    "        aggregated_processed_results_std['dist_nearest_train_mean'].append(np.std(selection['dist_nearest_train_mean'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['inst_regret_test'].append(np.std(selection['inst_regret_test'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['inst_regret_pool'].append(np.std(selection['inst_regret_pool'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['tot_regret_test'].append(np.std(selection['tot_regret_test'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['tot_regret_pool'].append(np.std(selection['tot_regret_pool'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['calibration_mse'].append(np.std(selection['calibration_mse'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['sharpness'].append(np.std(selection['sharpness'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['x_opt_dist_test'].append(np.std(selection['x_opt_dist_test'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['x_opt_dist_pool'].append(np.std(selection['x_opt_dist_pool'])/np.sqrt(seeds))\n",
    "#Same seed and same dataset are ranked together.\n",
    "df = pd.DataFrame.from_dict(aggregated_processed_results_std)\n",
    "df = df.sort_values('inst_regret_pool')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db12817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surrogate</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE</td>\n",
       "      <td>1.530303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>1.964646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>1.979377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BNN</td>\n",
       "      <td>2.843855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Surrogate      Rank\n",
       "1        DE  1.530303\n",
       "3        RF  1.964646\n",
       "2        GP  1.979377\n",
       "0       BNN  2.843855"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Instantaneous regret of pool rankings of surrogates alone.\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "exp_dict = {'surrogate': [], 'acquisition': [], 'seed':[], 'data':[], 'dist_nearest_train':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "main_directory=\"./results_real_data/\"\n",
    "subdirectories = ['results_FashionMNIST/', \"results_FashionMNIST_CNN/\", 'results_mnist/', 'results_MNIST_CNN/', 'results_News/', 'results_SVM/']\n",
    "for subdirectory in subdirectories:\n",
    "    full_path = os.path.join(main_directory, subdirectory)\n",
    "    for foldername in os.listdir(full_path):\n",
    "        folder = os.path.join(full_path, foldername)\n",
    "        if os.path.isdir(folder):\n",
    "            for filename in os.listdir(folder):\n",
    "                if filename.find(\"parameters\") != -1:\n",
    "                    json_file = open(os.path.join(folder, filename))\n",
    "                    params = json.load(json_file)\n",
    "                elif filename.find(\"metrics\") != -1:\n",
    "                    json_file = open(os.path.join(folder, filename))\n",
    "                    metrics = json.load(json_file)\n",
    "            if params['bo'] == True:\n",
    "                exp_dict['surrogate'].append(params['surrogate'])\n",
    "                exp_dict['acquisition'].append(params['acquisition'])\n",
    "                exp_dict['data'].append(params['data_name'])\n",
    "                exp_dict['dist_nearest_train'].append(metrics['next_sample_train_distance'])\n",
    "                exp_dict['inst_regret_test'].append(metrics['y_regret_test'])\n",
    "                exp_dict['inst_regret_pool'].append(metrics['y_regret_pool'])\n",
    "                exp_dict['tot_regret_test'].append(np.cumsum(metrics['y_regret_test']))\n",
    "                exp_dict['tot_regret_pool'].append(np.cumsum(metrics['y_regret_pool']))\n",
    "                exp_dict['x_opt_dist_pool'].append(metrics['x_y_opt_dist_pool'])\n",
    "                exp_dict['x_opt_dist_test'].append(metrics['x_y_opt_dist_test'])\n",
    "                exp_dict['sharpness'].append(metrics['mean_sharpness'])\n",
    "                exp_dict['calibration_mse'].append(metrics['y_calibration_mse'])\n",
    "                exp_dict['seed'].append(params['seed'])\n",
    "df = pd.DataFrame.from_dict(exp_dict)\n",
    "processed_results = {'surrogate': [], 'acquisition': [], 'seed':[], 'data':[], 'dist_nearest_train_mean':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for index, row in df.iterrows():\n",
    "    processed_results['surrogate'].append(row['surrogate'])\n",
    "    processed_results['acquisition'].append(row['acquisition'])\n",
    "    processed_results['data'].append(row['data'])\n",
    "    processed_results['seed'].append(row['seed'])\n",
    "    processed_results['dist_nearest_train_mean'].append(np.array(row['dist_nearest_train']).mean()) #Mean across one BO run.\n",
    "    processed_results['inst_regret_pool'].append(np.array(row['inst_regret_pool'])[-1]) #Last iter.\n",
    "    processed_results['inst_regret_test'].append(np.array(row['inst_regret_test'])[-1]) #Last iter.\n",
    "    processed_results['tot_regret_test'].append(np.array(row['tot_regret_test'])[-1]) #Last iter.\n",
    "    processed_results['tot_regret_pool'].append(np.array(row['tot_regret_pool'])[-1]) #Last iter.\n",
    "    processed_results['calibration_mse'].append(np.array(row['calibration_mse']).mean()) #Mean Calibration MSE over run.\n",
    "    processed_results['sharpness'].append(np.array(row['sharpness']).mean()) #Mean sharpness over run.\n",
    "    processed_results['x_opt_dist_test'].append(np.array(row['x_opt_dist_test'])[-1])\n",
    "    processed_results['x_opt_dist_pool'].append(np.array(row['x_opt_dist_pool'])[-1])\n",
    "#Same seed and same dataset are ranked together.\n",
    "df = pd.DataFrame.from_dict(processed_results)\n",
    "seeds = np.arange(99)+1\n",
    "datasets = ['fashionmnist', 'fashionmnist_cnn', 'mnist', 'mnist_cnn', 'news', 'svm_wine']\n",
    "acqs = ['UCB', 'TS', 'EI', 'RS']\n",
    "for seed in seeds:\n",
    "    for dataset in datasets:\n",
    "        for acq in acqs:\n",
    "            #For one problem and one seed, we get a ranking going from 1-16 (depending on ties) since there are 4 surrogates and 4 acqs.\n",
    "            selection = df.loc[(df['data']==dataset) & (df['seed']==seed) & (df['acquisition']==acq)]\n",
    "            df.loc[((df['data']==dataset) & (df['seed']==seed) & (df['acquisition']==acq)),'min_rank'] = selection['inst_regret_pool'].rank(method=\"min\")\n",
    "surrogates = ['BNN', 'DE', 'GP', 'RF']\n",
    "ranking_dict  = {'Surrogate':[], 'Rank':[]}\n",
    "for surrogate in surrogates:\n",
    "    ranking_dict['Rank'].append(df.loc[((df['surrogate']==surrogate)),'min_rank'].mean())\n",
    "    ranking_dict['Surrogate'].append(surrogate)\n",
    "display(pd.DataFrame.from_dict(ranking_dict).sort_values('Rank'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f36179c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run synthetic experiments.\n",
    "#Standard error of the mean p metrics.\n",
    "#Papers on Thompson Sampling for GPs vs RFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1e362832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surrogate</th>\n",
       "      <th>acquisition</th>\n",
       "      <th>dist_nearest_train_mean</th>\n",
       "      <th>inst_regret_test</th>\n",
       "      <th>inst_regret_pool</th>\n",
       "      <th>tot_regret_test</th>\n",
       "      <th>tot_regret_pool</th>\n",
       "      <th>calibration_mse</th>\n",
       "      <th>sharpness</th>\n",
       "      <th>x_opt_dist_test</th>\n",
       "      <th>x_opt_dist_pool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.802572</td>\n",
       "      <td>0.146148</td>\n",
       "      <td>0.029479</td>\n",
       "      <td>21.926112</td>\n",
       "      <td>11.797176</td>\n",
       "      <td>0.017731</td>\n",
       "      <td>-0.364803</td>\n",
       "      <td>1.528918</td>\n",
       "      <td>0.641151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GP</td>\n",
       "      <td>EI</td>\n",
       "      <td>1.153731</td>\n",
       "      <td>0.147055</td>\n",
       "      <td>0.030331</td>\n",
       "      <td>21.426844</td>\n",
       "      <td>11.058687</td>\n",
       "      <td>0.017027</td>\n",
       "      <td>-0.301464</td>\n",
       "      <td>1.588313</td>\n",
       "      <td>0.685210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DE</td>\n",
       "      <td>EI</td>\n",
       "      <td>0.963842</td>\n",
       "      <td>0.154234</td>\n",
       "      <td>0.040652</td>\n",
       "      <td>29.090840</td>\n",
       "      <td>20.801825</td>\n",
       "      <td>0.030715</td>\n",
       "      <td>-0.378963</td>\n",
       "      <td>1.608701</td>\n",
       "      <td>0.860884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DE</td>\n",
       "      <td>TS</td>\n",
       "      <td>0.994144</td>\n",
       "      <td>0.153996</td>\n",
       "      <td>0.041751</td>\n",
       "      <td>29.528736</td>\n",
       "      <td>21.157625</td>\n",
       "      <td>0.028561</td>\n",
       "      <td>-0.363112</td>\n",
       "      <td>1.584890</td>\n",
       "      <td>0.891726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GP</td>\n",
       "      <td>TS</td>\n",
       "      <td>1.037890</td>\n",
       "      <td>0.161805</td>\n",
       "      <td>0.045383</td>\n",
       "      <td>38.141138</td>\n",
       "      <td>30.318247</td>\n",
       "      <td>0.009847</td>\n",
       "      <td>-0.481535</td>\n",
       "      <td>1.596132</td>\n",
       "      <td>0.778285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.932209</td>\n",
       "      <td>0.156758</td>\n",
       "      <td>0.046666</td>\n",
       "      <td>28.865475</td>\n",
       "      <td>20.493528</td>\n",
       "      <td>0.029794</td>\n",
       "      <td>-0.399292</td>\n",
       "      <td>1.612486</td>\n",
       "      <td>0.920664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>UCB</td>\n",
       "      <td>1.039217</td>\n",
       "      <td>0.182220</td>\n",
       "      <td>0.076547</td>\n",
       "      <td>36.897073</td>\n",
       "      <td>30.881769</td>\n",
       "      <td>0.025258</td>\n",
       "      <td>-0.389793</td>\n",
       "      <td>1.622044</td>\n",
       "      <td>1.206396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>EI</td>\n",
       "      <td>1.082921</td>\n",
       "      <td>0.198535</td>\n",
       "      <td>0.105573</td>\n",
       "      <td>39.568599</td>\n",
       "      <td>34.717738</td>\n",
       "      <td>0.024385</td>\n",
       "      <td>-0.385502</td>\n",
       "      <td>1.645271</td>\n",
       "      <td>1.348865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF</td>\n",
       "      <td>TS</td>\n",
       "      <td>1.236687</td>\n",
       "      <td>0.329111</td>\n",
       "      <td>0.303249</td>\n",
       "      <td>55.699297</td>\n",
       "      <td>53.852967</td>\n",
       "      <td>0.012501</td>\n",
       "      <td>-0.446860</td>\n",
       "      <td>1.690973</td>\n",
       "      <td>1.588226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BNN</td>\n",
       "      <td>UCB</td>\n",
       "      <td>1.202356</td>\n",
       "      <td>0.474158</td>\n",
       "      <td>0.427622</td>\n",
       "      <td>63.102326</td>\n",
       "      <td>59.712532</td>\n",
       "      <td>0.103321</td>\n",
       "      <td>0.839903</td>\n",
       "      <td>1.899033</td>\n",
       "      <td>1.649999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GP</td>\n",
       "      <td>RS</td>\n",
       "      <td>1.327538</td>\n",
       "      <td>0.521677</td>\n",
       "      <td>0.507667</td>\n",
       "      <td>69.436269</td>\n",
       "      <td>68.029409</td>\n",
       "      <td>0.005555</td>\n",
       "      <td>-0.263425</td>\n",
       "      <td>1.764976</td>\n",
       "      <td>1.788188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BNN</td>\n",
       "      <td>RS</td>\n",
       "      <td>1.327693</td>\n",
       "      <td>0.538902</td>\n",
       "      <td>0.523169</td>\n",
       "      <td>69.785265</td>\n",
       "      <td>68.339945</td>\n",
       "      <td>0.090477</td>\n",
       "      <td>1.231088</td>\n",
       "      <td>1.758943</td>\n",
       "      <td>1.743391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DE</td>\n",
       "      <td>RS</td>\n",
       "      <td>1.329183</td>\n",
       "      <td>0.555505</td>\n",
       "      <td>0.530007</td>\n",
       "      <td>72.059134</td>\n",
       "      <td>69.957179</td>\n",
       "      <td>0.011096</td>\n",
       "      <td>0.027023</td>\n",
       "      <td>1.791294</td>\n",
       "      <td>1.776133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RF</td>\n",
       "      <td>RS</td>\n",
       "      <td>1.330241</td>\n",
       "      <td>0.548485</td>\n",
       "      <td>0.534077</td>\n",
       "      <td>71.170021</td>\n",
       "      <td>69.768581</td>\n",
       "      <td>0.006540</td>\n",
       "      <td>-0.473289</td>\n",
       "      <td>1.731927</td>\n",
       "      <td>1.771968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BNN</td>\n",
       "      <td>TS</td>\n",
       "      <td>1.325467</td>\n",
       "      <td>0.653323</td>\n",
       "      <td>0.619959</td>\n",
       "      <td>77.812629</td>\n",
       "      <td>75.052365</td>\n",
       "      <td>0.095481</td>\n",
       "      <td>0.985095</td>\n",
       "      <td>1.913332</td>\n",
       "      <td>1.866494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>1.335860</td>\n",
       "      <td>0.836982</td>\n",
       "      <td>0.802454</td>\n",
       "      <td>89.463852</td>\n",
       "      <td>86.715612</td>\n",
       "      <td>0.118409</td>\n",
       "      <td>0.602290</td>\n",
       "      <td>2.057075</td>\n",
       "      <td>1.972658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   surrogate acquisition  dist_nearest_train_mean  inst_regret_test  \\\n",
       "2         GP         UCB                 0.802572          0.146148   \n",
       "10        GP          EI                 1.153731          0.147055   \n",
       "9         DE          EI                 0.963842          0.154234   \n",
       "5         DE          TS                 0.994144          0.153996   \n",
       "6         GP          TS                 1.037890          0.161805   \n",
       "1         DE         UCB                 0.932209          0.156758   \n",
       "3         RF         UCB                 1.039217          0.182220   \n",
       "11        RF          EI                 1.082921          0.198535   \n",
       "7         RF          TS                 1.236687          0.329111   \n",
       "0        BNN         UCB                 1.202356          0.474158   \n",
       "14        GP          RS                 1.327538          0.521677   \n",
       "12       BNN          RS                 1.327693          0.538902   \n",
       "13        DE          RS                 1.329183          0.555505   \n",
       "15        RF          RS                 1.330241          0.548485   \n",
       "4        BNN          TS                 1.325467          0.653323   \n",
       "8        BNN          EI                 1.335860          0.836982   \n",
       "\n",
       "    inst_regret_pool  tot_regret_test  tot_regret_pool  calibration_mse  \\\n",
       "2           0.029479        21.926112        11.797176         0.017731   \n",
       "10          0.030331        21.426844        11.058687         0.017027   \n",
       "9           0.040652        29.090840        20.801825         0.030715   \n",
       "5           0.041751        29.528736        21.157625         0.028561   \n",
       "6           0.045383        38.141138        30.318247         0.009847   \n",
       "1           0.046666        28.865475        20.493528         0.029794   \n",
       "3           0.076547        36.897073        30.881769         0.025258   \n",
       "11          0.105573        39.568599        34.717738         0.024385   \n",
       "7           0.303249        55.699297        53.852967         0.012501   \n",
       "0           0.427622        63.102326        59.712532         0.103321   \n",
       "14          0.507667        69.436269        68.029409         0.005555   \n",
       "12          0.523169        69.785265        68.339945         0.090477   \n",
       "13          0.530007        72.059134        69.957179         0.011096   \n",
       "15          0.534077        71.170021        69.768581         0.006540   \n",
       "4           0.619959        77.812629        75.052365         0.095481   \n",
       "8           0.802454        89.463852        86.715612         0.118409   \n",
       "\n",
       "    sharpness  x_opt_dist_test  x_opt_dist_pool  \n",
       "2   -0.364803         1.528918         0.641151  \n",
       "10  -0.301464         1.588313         0.685210  \n",
       "9   -0.378963         1.608701         0.860884  \n",
       "5   -0.363112         1.584890         0.891726  \n",
       "6   -0.481535         1.596132         0.778285  \n",
       "1   -0.399292         1.612486         0.920664  \n",
       "3   -0.389793         1.622044         1.206396  \n",
       "11  -0.385502         1.645271         1.348865  \n",
       "7   -0.446860         1.690973         1.588226  \n",
       "0    0.839903         1.899033         1.649999  \n",
       "14  -0.263425         1.764976         1.788188  \n",
       "12   1.231088         1.758943         1.743391  \n",
       "13   0.027023         1.791294         1.776133  \n",
       "15  -0.473289         1.731927         1.771968  \n",
       "4    0.985095         1.913332         1.866494  \n",
       "8    0.602290         2.057075         1.972658  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surrogate</th>\n",
       "      <th>acquisition</th>\n",
       "      <th>dist_nearest_train_mean</th>\n",
       "      <th>inst_regret_test</th>\n",
       "      <th>inst_regret_pool</th>\n",
       "      <th>tot_regret_test</th>\n",
       "      <th>tot_regret_pool</th>\n",
       "      <th>calibration_mse</th>\n",
       "      <th>sharpness</th>\n",
       "      <th>x_opt_dist_test</th>\n",
       "      <th>x_opt_dist_pool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GP</td>\n",
       "      <td>EI</td>\n",
       "      <td>0.071006</td>\n",
       "      <td>0.038091</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>4.614184</td>\n",
       "      <td>1.657328</td>\n",
       "      <td>0.001540</td>\n",
       "      <td>0.063524</td>\n",
       "      <td>0.138771</td>\n",
       "      <td>0.115872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.060304</td>\n",
       "      <td>0.038120</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>4.777725</td>\n",
       "      <td>1.974661</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.065027</td>\n",
       "      <td>0.136044</td>\n",
       "      <td>0.116612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DE</td>\n",
       "      <td>EI</td>\n",
       "      <td>0.072843</td>\n",
       "      <td>0.039019</td>\n",
       "      <td>0.011327</td>\n",
       "      <td>5.397064</td>\n",
       "      <td>3.185947</td>\n",
       "      <td>0.003169</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>0.138775</td>\n",
       "      <td>0.144192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DE</td>\n",
       "      <td>TS</td>\n",
       "      <td>0.074607</td>\n",
       "      <td>0.039095</td>\n",
       "      <td>0.011820</td>\n",
       "      <td>5.407602</td>\n",
       "      <td>3.168870</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.048478</td>\n",
       "      <td>0.134350</td>\n",
       "      <td>0.144248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.070813</td>\n",
       "      <td>0.039262</td>\n",
       "      <td>0.012897</td>\n",
       "      <td>5.404013</td>\n",
       "      <td>3.212026</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.050929</td>\n",
       "      <td>0.138801</td>\n",
       "      <td>0.155027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.072955</td>\n",
       "      <td>0.042907</td>\n",
       "      <td>0.020076</td>\n",
       "      <td>7.138876</td>\n",
       "      <td>5.796626</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>0.085323</td>\n",
       "      <td>0.132010</td>\n",
       "      <td>0.154606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GP</td>\n",
       "      <td>TS</td>\n",
       "      <td>0.080978</td>\n",
       "      <td>0.046584</td>\n",
       "      <td>0.023892</td>\n",
       "      <td>8.303307</td>\n",
       "      <td>6.589152</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.058989</td>\n",
       "      <td>0.136940</td>\n",
       "      <td>0.127254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>EI</td>\n",
       "      <td>0.075136</td>\n",
       "      <td>0.048399</td>\n",
       "      <td>0.028823</td>\n",
       "      <td>8.022790</td>\n",
       "      <td>6.788635</td>\n",
       "      <td>0.001755</td>\n",
       "      <td>0.082658</td>\n",
       "      <td>0.132777</td>\n",
       "      <td>0.155677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF</td>\n",
       "      <td>TS</td>\n",
       "      <td>0.083435</td>\n",
       "      <td>0.079445</td>\n",
       "      <td>0.074548</td>\n",
       "      <td>11.313991</td>\n",
       "      <td>10.702940</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.076372</td>\n",
       "      <td>0.134354</td>\n",
       "      <td>0.145385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BNN</td>\n",
       "      <td>UCB</td>\n",
       "      <td>0.084850</td>\n",
       "      <td>0.087058</td>\n",
       "      <td>0.088271</td>\n",
       "      <td>10.830463</td>\n",
       "      <td>10.738128</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.033730</td>\n",
       "      <td>0.131128</td>\n",
       "      <td>0.148726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GP</td>\n",
       "      <td>RS</td>\n",
       "      <td>0.082516</td>\n",
       "      <td>0.109321</td>\n",
       "      <td>0.103439</td>\n",
       "      <td>13.319291</td>\n",
       "      <td>12.573118</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.063756</td>\n",
       "      <td>0.125982</td>\n",
       "      <td>0.134355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BNN</td>\n",
       "      <td>RS</td>\n",
       "      <td>0.082511</td>\n",
       "      <td>0.115419</td>\n",
       "      <td>0.105981</td>\n",
       "      <td>13.607411</td>\n",
       "      <td>12.785586</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.042190</td>\n",
       "      <td>0.128304</td>\n",
       "      <td>0.127847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DE</td>\n",
       "      <td>RS</td>\n",
       "      <td>0.083007</td>\n",
       "      <td>0.116226</td>\n",
       "      <td>0.106891</td>\n",
       "      <td>13.811025</td>\n",
       "      <td>12.832681</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.033984</td>\n",
       "      <td>0.127038</td>\n",
       "      <td>0.131988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RF</td>\n",
       "      <td>RS</td>\n",
       "      <td>0.082671</td>\n",
       "      <td>0.113814</td>\n",
       "      <td>0.109263</td>\n",
       "      <td>13.620244</td>\n",
       "      <td>13.145845</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.081091</td>\n",
       "      <td>0.123590</td>\n",
       "      <td>0.130294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BNN</td>\n",
       "      <td>TS</td>\n",
       "      <td>0.084236</td>\n",
       "      <td>0.134162</td>\n",
       "      <td>0.129449</td>\n",
       "      <td>14.712334</td>\n",
       "      <td>14.186122</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.034718</td>\n",
       "      <td>0.130342</td>\n",
       "      <td>0.146801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>0.099354</td>\n",
       "      <td>0.155894</td>\n",
       "      <td>0.152066</td>\n",
       "      <td>16.084697</td>\n",
       "      <td>15.659780</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>0.041323</td>\n",
       "      <td>0.133138</td>\n",
       "      <td>0.148898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   surrogate acquisition  dist_nearest_train_mean  inst_regret_test  \\\n",
       "10        GP          EI                 0.071006          0.038091   \n",
       "2         GP         UCB                 0.060304          0.038120   \n",
       "9         DE          EI                 0.072843          0.039019   \n",
       "5         DE          TS                 0.074607          0.039095   \n",
       "1         DE         UCB                 0.070813          0.039262   \n",
       "3         RF         UCB                 0.072955          0.042907   \n",
       "6         GP          TS                 0.080978          0.046584   \n",
       "11        RF          EI                 0.075136          0.048399   \n",
       "7         RF          TS                 0.083435          0.079445   \n",
       "0        BNN         UCB                 0.084850          0.087058   \n",
       "14        GP          RS                 0.082516          0.109321   \n",
       "12       BNN          RS                 0.082511          0.115419   \n",
       "13        DE          RS                 0.083007          0.116226   \n",
       "15        RF          RS                 0.082671          0.113814   \n",
       "4        BNN          TS                 0.084236          0.134162   \n",
       "8        BNN          EI                 0.099354          0.155894   \n",
       "\n",
       "    inst_regret_pool  tot_regret_test  tot_regret_pool  calibration_mse  \\\n",
       "10          0.004946         4.614184         1.657328         0.001540   \n",
       "2           0.005022         4.777725         1.974661         0.001809   \n",
       "9           0.011327         5.397064         3.185947         0.003169   \n",
       "5           0.011820         5.407602         3.168870         0.002738   \n",
       "1           0.012897         5.404013         3.212026         0.003041   \n",
       "3           0.020076         7.138876         5.796626         0.001841   \n",
       "6           0.023892         8.303307         6.589152         0.000949   \n",
       "11          0.028823         8.022790         6.788635         0.001755   \n",
       "7           0.074548        11.313991        10.702940         0.000931   \n",
       "0           0.088271        10.830463        10.738128         0.005445   \n",
       "14          0.103439        13.319291        12.573118         0.000721   \n",
       "12          0.105981        13.607411        12.785586         0.002932   \n",
       "13          0.106891        13.811025        12.832681         0.000636   \n",
       "15          0.109263        13.620244        13.145845         0.000421   \n",
       "4           0.129449        14.712334        14.186122         0.003931   \n",
       "8           0.152066        16.084697        15.659780         0.005563   \n",
       "\n",
       "    sharpness  x_opt_dist_test  x_opt_dist_pool  \n",
       "10   0.063524         0.138771         0.115872  \n",
       "2    0.065027         0.136044         0.116612  \n",
       "9    0.049300         0.138775         0.144192  \n",
       "5    0.048478         0.134350         0.144248  \n",
       "1    0.050929         0.138801         0.155027  \n",
       "3    0.085323         0.132010         0.154606  \n",
       "6    0.058989         0.136940         0.127254  \n",
       "11   0.082658         0.132777         0.155677  \n",
       "7    0.076372         0.134354         0.145385  \n",
       "0    0.033730         0.131128         0.148726  \n",
       "14   0.063756         0.125982         0.134355  \n",
       "12   0.042190         0.128304         0.127847  \n",
       "13   0.033984         0.127038         0.131988  \n",
       "15   0.081091         0.123590         0.130294  \n",
       "4    0.034718         0.130342         0.146801  \n",
       "8    0.041323         0.133138         0.148898  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Metrics at final iteration of synth_data experiment with standard error of the mean reported in separate DataFrame.\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "exp_dict = {'surrogate': [], 'acquisition': [], 'seed':[], 'data':[], 'dist_nearest_train':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "main_directory=\"./results_synth_data/\"\n",
    "for foldername in os.listdir(main_directory):\n",
    "    folder = os.path.join(main_directory, foldername)\n",
    "    if os.path.isdir(folder):\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.find(\"parameters\") != -1:\n",
    "                json_file = open(os.path.join(folder, filename))\n",
    "                params = json.load(json_file)\n",
    "            elif filename.find(\"metrics\") != -1:\n",
    "                json_file = open(os.path.join(folder, filename))\n",
    "                metrics = json.load(json_file)\n",
    "        if params['bo'] == True:\n",
    "            exp_dict['surrogate'].append(params['surrogate'])\n",
    "            exp_dict['acquisition'].append(params['acquisition'])\n",
    "            exp_dict['data'].append(params['data_name'])\n",
    "            exp_dict['dist_nearest_train'].append(metrics['next_sample_train_distance'])\n",
    "            exp_dict['inst_regret_test'].append(metrics['f_regret_test'])\n",
    "            exp_dict['inst_regret_pool'].append(metrics['f_regret_pool'])\n",
    "            exp_dict['tot_regret_test'].append(np.cumsum(metrics['f_regret_test']))\n",
    "            exp_dict['tot_regret_pool'].append(np.cumsum(metrics['f_regret_pool']))\n",
    "            exp_dict['x_opt_dist_pool'].append(metrics['x_y_opt_dist_pool'])\n",
    "            exp_dict['x_opt_dist_test'].append(metrics['x_y_opt_dist_test'])\n",
    "            exp_dict['sharpness'].append(metrics['mean_sharpness'])\n",
    "            exp_dict['calibration_mse'].append(metrics['y_calibration_mse'])\n",
    "            exp_dict['seed'].append(params['seed'])\n",
    "df = pd.DataFrame.from_dict(exp_dict)\n",
    "processed_results = {'surrogate': [], 'acquisition': [], 'seed':[], 'data':[], 'dist_nearest_train_mean':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for index, row in df.iterrows():\n",
    "    processed_results['surrogate'].append(row['surrogate'])\n",
    "    processed_results['acquisition'].append(row['acquisition'])\n",
    "    processed_results['data'].append(row['data'])\n",
    "    processed_results['seed'].append(row['seed'])\n",
    "    processed_results['dist_nearest_train_mean'].append(np.array(row['dist_nearest_train']).mean()) #Mean across one BO run.\n",
    "    processed_results['inst_regret_pool'].append(np.array(row['inst_regret_pool'])[-1]) #Last iter.\n",
    "    processed_results['inst_regret_test'].append(np.array(row['inst_regret_test'])[-1]) #Last iter.\n",
    "    processed_results['tot_regret_test'].append(np.array(row['tot_regret_test'])[-1]) #Last iter.\n",
    "    processed_results['tot_regret_pool'].append(np.array(row['tot_regret_pool'])[-1]) #Last iter.\n",
    "    processed_results['calibration_mse'].append(np.array(row['calibration_mse']).mean(axis=0)) #Mean Calibration MSE over run.\n",
    "    processed_results['sharpness'].append(np.array(row['sharpness']).mean()) #Mean sharpness over run.\n",
    "    processed_results['x_opt_dist_test'].append(np.array(row['x_opt_dist_test'])[-1])\n",
    "    processed_results['x_opt_dist_pool'].append(np.array(row['x_opt_dist_pool'])[-1])\n",
    "df = pd.DataFrame.from_dict(processed_results)\n",
    "acqs = ['UCB', 'TS', 'EI', 'RS']\n",
    "surrogates = ['BNN', 'DE', 'GP', 'RF']\n",
    "seeds = 99\n",
    "aggregated_processed_results = {'surrogate': [], 'acquisition': [], 'dist_nearest_train_mean':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for acq in acqs:\n",
    "    for surrogate in surrogates:\n",
    "        selection = df.loc[((df['acquisition']==acq) & (df['surrogate']==surrogate))]\n",
    "        aggregated_processed_results['surrogate'].append(surrogate)\n",
    "        aggregated_processed_results['acquisition'].append(acq)\n",
    "        aggregated_processed_results['dist_nearest_train_mean'].append(np.mean(selection['dist_nearest_train_mean']))\n",
    "        aggregated_processed_results['inst_regret_test'].append(np.mean(selection['inst_regret_test']))\n",
    "        aggregated_processed_results['inst_regret_pool'].append(np.mean(selection['inst_regret_pool']))\n",
    "        aggregated_processed_results['tot_regret_test'].append(np.mean(selection['tot_regret_test']))\n",
    "        aggregated_processed_results['tot_regret_pool'].append(np.mean(selection['tot_regret_pool']))\n",
    "        aggregated_processed_results['calibration_mse'].append(np.mean(selection['calibration_mse']))\n",
    "        aggregated_processed_results['sharpness'].append(np.mean(selection['sharpness']))\n",
    "        aggregated_processed_results['x_opt_dist_test'].append(np.mean(selection['x_opt_dist_test']))\n",
    "        aggregated_processed_results['x_opt_dist_pool'].append(np.mean(selection['x_opt_dist_pool']))\n",
    "df2 = pd.DataFrame.from_dict(aggregated_processed_results)\n",
    "df2 = df2.sort_values('inst_regret_pool')\n",
    "display(df2)\n",
    "acqs = ['UCB', 'TS', 'EI', 'RS']\n",
    "surrogates = ['BNN', 'DE', 'GP', 'RF']\n",
    "aggregated_processed_results_std = {'surrogate': [], 'acquisition': [], 'dist_nearest_train_mean':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for acq in acqs:\n",
    "    for surrogate in surrogates:\n",
    "        selection = df.loc[((df['acquisition']==acq) & (df['surrogate']==surrogate))]\n",
    "        aggregated_processed_results_std['surrogate'].append(surrogate)\n",
    "        aggregated_processed_results_std['acquisition'].append(acq)\n",
    "        aggregated_processed_results_std['dist_nearest_train_mean'].append(np.std(selection['dist_nearest_train_mean'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['inst_regret_test'].append(np.std(selection['inst_regret_test'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['inst_regret_pool'].append(np.std(selection['inst_regret_pool'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['tot_regret_test'].append(np.std(selection['tot_regret_test'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['tot_regret_pool'].append(np.std(selection['tot_regret_pool'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['calibration_mse'].append(np.std(selection['calibration_mse'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['sharpness'].append(np.std(selection['sharpness'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['x_opt_dist_test'].append(np.std(selection['x_opt_dist_test'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['x_opt_dist_pool'].append(np.std(selection['x_opt_dist_pool'])/np.sqrt(seeds))\n",
    "#Same seed and same dataset are ranked together.\n",
    "df = pd.DataFrame.from_dict(aggregated_processed_results_std)\n",
    "df = df.sort_values('inst_regret_pool')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d3cfb694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surrogate</th>\n",
       "      <th>acquisition</th>\n",
       "      <th>problem_idx</th>\n",
       "      <th>dist_nearest_train_mean</th>\n",
       "      <th>inst_regret_test</th>\n",
       "      <th>inst_regret_pool</th>\n",
       "      <th>tot_regret_test</th>\n",
       "      <th>tot_regret_pool</th>\n",
       "      <th>calibration_mse</th>\n",
       "      <th>sharpness</th>\n",
       "      <th>x_opt_dist_test</th>\n",
       "      <th>x_opt_dist_pool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>5</td>\n",
       "      <td>0.760505</td>\n",
       "      <td>0.194974</td>\n",
       "      <td>0.008799</td>\n",
       "      <td>32.015221</td>\n",
       "      <td>15.898640</td>\n",
       "      <td>0.013035</td>\n",
       "      <td>-0.526292</td>\n",
       "      <td>1.202951</td>\n",
       "      <td>0.139408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>7</td>\n",
       "      <td>0.806685</td>\n",
       "      <td>0.103903</td>\n",
       "      <td>0.009242</td>\n",
       "      <td>16.105789</td>\n",
       "      <td>9.441714</td>\n",
       "      <td>0.011064</td>\n",
       "      <td>-0.312176</td>\n",
       "      <td>1.397290</td>\n",
       "      <td>0.324058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DE</td>\n",
       "      <td>UCB</td>\n",
       "      <td>5</td>\n",
       "      <td>0.858026</td>\n",
       "      <td>0.196411</td>\n",
       "      <td>0.013127</td>\n",
       "      <td>40.310023</td>\n",
       "      <td>27.730798</td>\n",
       "      <td>0.015721</td>\n",
       "      <td>-0.519250</td>\n",
       "      <td>1.240467</td>\n",
       "      <td>0.199844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>GP</td>\n",
       "      <td>TS</td>\n",
       "      <td>5</td>\n",
       "      <td>0.951921</td>\n",
       "      <td>0.197318</td>\n",
       "      <td>0.014596</td>\n",
       "      <td>49.547582</td>\n",
       "      <td>37.507174</td>\n",
       "      <td>0.007204</td>\n",
       "      <td>-0.500218</td>\n",
       "      <td>1.335132</td>\n",
       "      <td>0.165933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>DE</td>\n",
       "      <td>EI</td>\n",
       "      <td>5</td>\n",
       "      <td>0.887361</td>\n",
       "      <td>0.199711</td>\n",
       "      <td>0.017003</td>\n",
       "      <td>41.177085</td>\n",
       "      <td>28.917780</td>\n",
       "      <td>0.016763</td>\n",
       "      <td>-0.493869</td>\n",
       "      <td>1.229873</td>\n",
       "      <td>0.247400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>BNN</td>\n",
       "      <td>RS</td>\n",
       "      <td>3</td>\n",
       "      <td>1.326504</td>\n",
       "      <td>1.084053</td>\n",
       "      <td>1.048210</td>\n",
       "      <td>139.250707</td>\n",
       "      <td>136.035021</td>\n",
       "      <td>0.092682</td>\n",
       "      <td>1.239733</td>\n",
       "      <td>1.430291</td>\n",
       "      <td>1.464125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>BNN</td>\n",
       "      <td>TS</td>\n",
       "      <td>5</td>\n",
       "      <td>1.311772</td>\n",
       "      <td>1.082946</td>\n",
       "      <td>1.050915</td>\n",
       "      <td>122.102813</td>\n",
       "      <td>119.577338</td>\n",
       "      <td>0.078833</td>\n",
       "      <td>0.969064</td>\n",
       "      <td>1.609469</td>\n",
       "      <td>1.600280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>BNN</td>\n",
       "      <td>TS</td>\n",
       "      <td>3</td>\n",
       "      <td>1.311362</td>\n",
       "      <td>1.229774</td>\n",
       "      <td>1.178511</td>\n",
       "      <td>147.663297</td>\n",
       "      <td>143.590477</td>\n",
       "      <td>0.100086</td>\n",
       "      <td>0.978061</td>\n",
       "      <td>1.686355</td>\n",
       "      <td>1.585484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>5</td>\n",
       "      <td>1.325672</td>\n",
       "      <td>1.226082</td>\n",
       "      <td>1.191041</td>\n",
       "      <td>133.094686</td>\n",
       "      <td>131.065518</td>\n",
       "      <td>0.092761</td>\n",
       "      <td>0.575001</td>\n",
       "      <td>1.652024</td>\n",
       "      <td>1.472385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>3</td>\n",
       "      <td>1.343392</td>\n",
       "      <td>1.666969</td>\n",
       "      <td>1.610340</td>\n",
       "      <td>176.862535</td>\n",
       "      <td>172.499753</td>\n",
       "      <td>0.122904</td>\n",
       "      <td>0.537897</td>\n",
       "      <td>1.932004</td>\n",
       "      <td>1.838923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows  12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    surrogate acquisition  problem_idx  dist_nearest_train_mean  \\\n",
       "18         GP         UCB            5                 0.760505   \n",
       "26         GP         UCB            7                 0.806685   \n",
       "17         DE         UCB            5                 0.858026   \n",
       "58         GP          TS            5                 0.951921   \n",
       "97         DE          EI            5                 0.887361   \n",
       "..        ...         ...          ...                      ...   \n",
       "128       BNN          RS            3                 1.326504   \n",
       "56        BNN          TS            5                 1.311772   \n",
       "48        BNN          TS            3                 1.311362   \n",
       "96        BNN          EI            5                 1.325672   \n",
       "88        BNN          EI            3                 1.343392   \n",
       "\n",
       "     inst_regret_test  inst_regret_pool  tot_regret_test  tot_regret_pool  \\\n",
       "18           0.194974          0.008799        32.015221        15.898640   \n",
       "26           0.103903          0.009242        16.105789         9.441714   \n",
       "17           0.196411          0.013127        40.310023        27.730798   \n",
       "58           0.197318          0.014596        49.547582        37.507174   \n",
       "97           0.199711          0.017003        41.177085        28.917780   \n",
       "..                ...               ...              ...              ...   \n",
       "128          1.084053          1.048210       139.250707       136.035021   \n",
       "56           1.082946          1.050915       122.102813       119.577338   \n",
       "48           1.229774          1.178511       147.663297       143.590477   \n",
       "96           1.226082          1.191041       133.094686       131.065518   \n",
       "88           1.666969          1.610340       176.862535       172.499753   \n",
       "\n",
       "     calibration_mse  sharpness  x_opt_dist_test  x_opt_dist_pool  \n",
       "18          0.013035  -0.526292         1.202951         0.139408  \n",
       "26          0.011064  -0.312176         1.397290         0.324058  \n",
       "17          0.015721  -0.519250         1.240467         0.199844  \n",
       "58          0.007204  -0.500218         1.335132         0.165933  \n",
       "97          0.016763  -0.493869         1.229873         0.247400  \n",
       "..               ...        ...              ...              ...  \n",
       "128         0.092682   1.239733         1.430291         1.464125  \n",
       "56          0.078833   0.969064         1.609469         1.600280  \n",
       "48          0.100086   0.978061         1.686355         1.585484  \n",
       "96          0.092761   0.575001         1.652024         1.472385  \n",
       "88          0.122904   0.537897         1.932004         1.838923  \n",
       "\n",
       "[160 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [49]\u001b[0m, in \u001b[0;36m<cell line: 93>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     91\u001b[0m         aggregated_processed_results_std[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_opt_dist_pool\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mstd(selection[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx_opt_dist_pool\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m/\u001b[39mnp\u001b[38;5;241m.\u001b[39msqrt(seeds))\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m#Same seed and same dataset are ranked together.\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43maggregated_processed_results_std\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minst_regret_pool\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     95\u001b[0m display(df)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/frame.py:1677\u001b[0m, in \u001b[0;36mDataFrame.from_dict\u001b[0;34m(cls, data, orient, dtype, columns)\u001b[0m\n\u001b[1;32m   1674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124monly recognize index or columns for orient\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1677\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1679\u001b[0m     realdata \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/frame.py:636\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    630\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    631\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    632\u001b[0m     )\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 636\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/internals/construction.py:502\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    494\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    495\u001b[0m         x\n\u001b[1;32m    496\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m    497\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m x\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m    499\u001b[0m     ]\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# TODO: can we get rid of the dt64tz special case above?\u001b[39;00m\n\u001b[0;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/internals/construction.py:120\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 120\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    122\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/pandas/core/internals/construction.py:674\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    672\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 674\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    678\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    679\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "#Metrics at final iteration of synth_data experiment with standard error of the mean reported in separate DataFrame.\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "exp_dict = {'surrogate': [], 'acquisition': [], 'seed':[], 'problem_idx':[], 'dim':[], 'dist_nearest_train':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "main_directory=\"./results_synth_data/\"\n",
    "for foldername in os.listdir(main_directory):\n",
    "    folder = os.path.join(main_directory, foldername)\n",
    "    if os.path.isdir(folder):\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.find(\"parameters\") != -1:\n",
    "                json_file = open(os.path.join(folder, filename))\n",
    "                params = json.load(json_file)\n",
    "            elif filename.find(\"metrics\") != -1:\n",
    "                json_file = open(os.path.join(folder, filename))\n",
    "                metrics = json.load(json_file)\n",
    "        if params['bo'] == True:\n",
    "            exp_dict['surrogate'].append(params['surrogate'])\n",
    "            exp_dict['acquisition'].append(params['acquisition'])\n",
    "            exp_dict['problem_idx'].append(params['problem_idx'])\n",
    "            exp_dict['dim'].append(params['d'])\n",
    "            exp_dict['dist_nearest_train'].append(metrics['next_sample_train_distance'])\n",
    "            exp_dict['inst_regret_test'].append(metrics['y_regret_test'])\n",
    "            exp_dict['inst_regret_pool'].append(metrics['y_regret_pool'])\n",
    "            exp_dict['tot_regret_test'].append(np.cumsum(metrics['y_regret_test']))\n",
    "            exp_dict['tot_regret_pool'].append(np.cumsum(metrics['y_regret_pool']))\n",
    "            exp_dict['x_opt_dist_pool'].append(metrics['x_y_opt_dist_pool'])\n",
    "            exp_dict['x_opt_dist_test'].append(metrics['x_y_opt_dist_test'])\n",
    "            exp_dict['sharpness'].append(metrics['mean_sharpness'])\n",
    "            exp_dict['calibration_mse'].append(metrics['y_calibration_mse'])\n",
    "            exp_dict['seed'].append(params['seed'])\n",
    "df = pd.DataFrame.from_dict(exp_dict)\n",
    "processed_results = {'surrogate': [], 'acquisition': [], 'seed':[], 'problem_idx':[], 'dim':[], 'dist_nearest_train_mean':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for index, row in df.iterrows():\n",
    "    processed_results['surrogate'].append(row['surrogate'])\n",
    "    processed_results['acquisition'].append(row['acquisition'])\n",
    "    processed_results['problem_idx'].append(row['problem_idx'])\n",
    "    processed_results['dim'].append(row['dim'])\n",
    "    processed_results['seed'].append(row['seed'])\n",
    "    processed_results['dist_nearest_train_mean'].append(np.array(row['dist_nearest_train']).mean()) #Mean across one BO run.\n",
    "    processed_results['inst_regret_pool'].append(np.array(row['inst_regret_pool'])[-1]) #Last iter.\n",
    "    processed_results['inst_regret_test'].append(np.array(row['inst_regret_test'])[-1]) #Last iter.\n",
    "    processed_results['tot_regret_test'].append(np.array(row['tot_regret_test'])[-1]) #Last iter.\n",
    "    processed_results['tot_regret_pool'].append(np.array(row['tot_regret_pool'])[-1]) #Last iter.\n",
    "    processed_results['calibration_mse'].append(np.array(row['calibration_mse']).mean()) #Mean Calibration MSE over run.\n",
    "    processed_results['sharpness'].append(np.array(row['sharpness']).mean()) #Mean sharpness over run.\n",
    "    processed_results['x_opt_dist_test'].append(np.array(row['x_opt_dist_test'])[-1])\n",
    "    processed_results['x_opt_dist_pool'].append(np.array(row['x_opt_dist_pool'])[-1])\n",
    "df = pd.DataFrame.from_dict(processed_results)\n",
    "acqs = ['UCB', 'TS', 'EI', 'RS']\n",
    "surrogates = ['BNN', 'DE', 'GP', 'RF']\n",
    "problem_idxs = np.arange(10)+1\n",
    "seeds = 10\n",
    "aggregated_processed_results = {'surrogate': [], 'acquisition': [], 'problem_idx': [], 'dist_nearest_train_mean':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for acq in acqs:\n",
    "    for problem_idx in problem_idxs:\n",
    "        for surrogate in surrogates:\n",
    "            selection = df.loc[((df['acquisition']==acq) & (df['surrogate']==surrogate)& (df['problem_idx']==problem_idx))]\n",
    "            aggregated_processed_results['surrogate'].append(surrogate)\n",
    "            aggregated_processed_results['acquisition'].append(acq)\n",
    "            aggregated_processed_results['problem_idx'].append(problem_idx)\n",
    "            aggregated_processed_results['dist_nearest_train_mean'].append(np.mean(selection['dist_nearest_train_mean']))\n",
    "            aggregated_processed_results['inst_regret_test'].append(np.mean(selection['inst_regret_test']))\n",
    "            aggregated_processed_results['inst_regret_pool'].append(np.mean(selection['inst_regret_pool']))\n",
    "            aggregated_processed_results['tot_regret_test'].append(np.mean(selection['tot_regret_test']))\n",
    "            aggregated_processed_results['tot_regret_pool'].append(np.mean(selection['tot_regret_pool']))\n",
    "            aggregated_processed_results['calibration_mse'].append(np.mean(selection['calibration_mse']))\n",
    "            aggregated_processed_results['sharpness'].append(np.mean(selection['sharpness']))\n",
    "            aggregated_processed_results['x_opt_dist_test'].append(np.mean(selection['x_opt_dist_test']))\n",
    "            aggregated_processed_results['x_opt_dist_pool'].append(np.mean(selection['x_opt_dist_pool']))\n",
    "df2 = pd.DataFrame.from_dict(aggregated_processed_results)\n",
    "df2 = df2.sort_values('inst_regret_pool')\n",
    "display(df2)\n",
    "aggregated_processed_results_std = {'surrogate': [], 'acquisition': [], 'problem_idx': [], 'dist_nearest_train_mean':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for acq in acqs:\n",
    "    for surrogate in surrogates:\n",
    "        selection = df.loc[((df['acquisition']==acq) & (df['surrogate']==surrogate)& (df['problem_idx']==problem_idx))]\n",
    "        aggregated_processed_results_std['surrogate'].append(surrogate)\n",
    "        aggregated_processed_results_std['acquisition'].append(acq)\n",
    "        aggregated_processed_results['problem_idx'].append(problem_idx)\n",
    "        aggregated_processed_results_std['dist_nearest_train_mean'].append(np.std(selection['dist_nearest_train_mean'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['inst_regret_test'].append(np.std(selection['inst_regret_test'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['inst_regret_pool'].append(np.std(selection['inst_regret_pool'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['tot_regret_test'].append(np.std(selection['tot_regret_test'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['tot_regret_pool'].append(np.std(selection['tot_regret_pool'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['calibration_mse'].append(np.std(selection['calibration_mse'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['sharpness'].append(np.std(selection['sharpness'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['x_opt_dist_test'].append(np.std(selection['x_opt_dist_test'])/np.sqrt(seeds))\n",
    "        aggregated_processed_results_std['x_opt_dist_pool'].append(np.std(selection['x_opt_dist_pool'])/np.sqrt(seeds))\n",
    "#Same seed and same dataset are ranked together.\n",
    "df = pd.DataFrame.from_dict(aggregated_processed_results_std)\n",
    "df = df.sort_values('inst_regret_pool')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e461208b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surrogate</th>\n",
       "      <th>acquisition</th>\n",
       "      <th>problem_idx</th>\n",
       "      <th>dist_nearest_train_mean</th>\n",
       "      <th>inst_regret_test</th>\n",
       "      <th>inst_regret_pool</th>\n",
       "      <th>tot_regret_test</th>\n",
       "      <th>tot_regret_pool</th>\n",
       "      <th>calibration_mse</th>\n",
       "      <th>sharpness</th>\n",
       "      <th>x_opt_dist_test</th>\n",
       "      <th>x_opt_dist_pool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>5</td>\n",
       "      <td>0.761</td>\n",
       "      <td>0.195</td>\n",
       "      <td>0.009</td>\n",
       "      <td>32.015</td>\n",
       "      <td>15.899</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.526</td>\n",
       "      <td>1.203</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>7</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.009</td>\n",
       "      <td>16.106</td>\n",
       "      <td>9.442</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>1.397</td>\n",
       "      <td>0.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DE</td>\n",
       "      <td>UCB</td>\n",
       "      <td>5</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.013</td>\n",
       "      <td>40.310</td>\n",
       "      <td>27.731</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.519</td>\n",
       "      <td>1.240</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>GP</td>\n",
       "      <td>TS</td>\n",
       "      <td>5</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.015</td>\n",
       "      <td>49.548</td>\n",
       "      <td>37.507</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>1.335</td>\n",
       "      <td>0.166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>DE</td>\n",
       "      <td>EI</td>\n",
       "      <td>5</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.017</td>\n",
       "      <td>41.177</td>\n",
       "      <td>28.918</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>1.230</td>\n",
       "      <td>0.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>6</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.017</td>\n",
       "      <td>24.558</td>\n",
       "      <td>15.272</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>1.581</td>\n",
       "      <td>0.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>GP</td>\n",
       "      <td>TS</td>\n",
       "      <td>7</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.018</td>\n",
       "      <td>23.813</td>\n",
       "      <td>18.917</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.368</td>\n",
       "      <td>1.451</td>\n",
       "      <td>0.399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>GP</td>\n",
       "      <td>EI</td>\n",
       "      <td>5</td>\n",
       "      <td>1.138</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.019</td>\n",
       "      <td>30.359</td>\n",
       "      <td>14.299</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>1.283</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>GP</td>\n",
       "      <td>EI</td>\n",
       "      <td>6</td>\n",
       "      <td>1.093</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.019</td>\n",
       "      <td>23.994</td>\n",
       "      <td>14.839</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>1.634</td>\n",
       "      <td>0.388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>DE</td>\n",
       "      <td>TS</td>\n",
       "      <td>5</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.020</td>\n",
       "      <td>41.451</td>\n",
       "      <td>28.908</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.465</td>\n",
       "      <td>1.227</td>\n",
       "      <td>0.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>3</td>\n",
       "      <td>0.766</td>\n",
       "      <td>0.299</td>\n",
       "      <td>0.020</td>\n",
       "      <td>44.191</td>\n",
       "      <td>19.891</td>\n",
       "      <td>0.018</td>\n",
       "      <td>-0.673</td>\n",
       "      <td>1.128</td>\n",
       "      <td>0.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>DE</td>\n",
       "      <td>EI</td>\n",
       "      <td>7</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.020</td>\n",
       "      <td>20.733</td>\n",
       "      <td>15.744</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.332</td>\n",
       "      <td>1.533</td>\n",
       "      <td>0.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>GP</td>\n",
       "      <td>TS</td>\n",
       "      <td>6</td>\n",
       "      <td>1.024</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.020</td>\n",
       "      <td>54.272</td>\n",
       "      <td>46.382</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.470</td>\n",
       "      <td>1.624</td>\n",
       "      <td>0.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>GP</td>\n",
       "      <td>EI</td>\n",
       "      <td>7</td>\n",
       "      <td>1.115</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.022</td>\n",
       "      <td>17.381</td>\n",
       "      <td>10.378</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>1.514</td>\n",
       "      <td>0.318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>DE</td>\n",
       "      <td>UCB</td>\n",
       "      <td>8</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.026</td>\n",
       "      <td>18.906</td>\n",
       "      <td>15.624</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>1.520</td>\n",
       "      <td>0.675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>DE</td>\n",
       "      <td>TS</td>\n",
       "      <td>8</td>\n",
       "      <td>0.939</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.027</td>\n",
       "      <td>18.974</td>\n",
       "      <td>15.459</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>1.459</td>\n",
       "      <td>0.467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>8</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.027</td>\n",
       "      <td>12.803</td>\n",
       "      <td>8.998</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>1.449</td>\n",
       "      <td>0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>GP</td>\n",
       "      <td>EI</td>\n",
       "      <td>3</td>\n",
       "      <td>1.190</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.028</td>\n",
       "      <td>44.283</td>\n",
       "      <td>19.967</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.549</td>\n",
       "      <td>1.166</td>\n",
       "      <td>0.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>9</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.028</td>\n",
       "      <td>29.694</td>\n",
       "      <td>16.050</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.460</td>\n",
       "      <td>1.348</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>DE</td>\n",
       "      <td>UCB</td>\n",
       "      <td>7</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.029</td>\n",
       "      <td>21.107</td>\n",
       "      <td>15.519</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0.340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>GP</td>\n",
       "      <td>TS</td>\n",
       "      <td>8</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.030</td>\n",
       "      <td>25.484</td>\n",
       "      <td>22.632</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>1.360</td>\n",
       "      <td>0.661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>DE</td>\n",
       "      <td>TS</td>\n",
       "      <td>7</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.030</td>\n",
       "      <td>20.337</td>\n",
       "      <td>16.009</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>1.450</td>\n",
       "      <td>0.525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>GP</td>\n",
       "      <td>EI</td>\n",
       "      <td>8</td>\n",
       "      <td>1.059</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.032</td>\n",
       "      <td>13.592</td>\n",
       "      <td>9.701</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>1.384</td>\n",
       "      <td>0.535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>DE</td>\n",
       "      <td>EI</td>\n",
       "      <td>6</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.033</td>\n",
       "      <td>32.708</td>\n",
       "      <td>25.079</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>1.647</td>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>DE</td>\n",
       "      <td>TS</td>\n",
       "      <td>6</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.035</td>\n",
       "      <td>36.406</td>\n",
       "      <td>29.163</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.388</td>\n",
       "      <td>1.602</td>\n",
       "      <td>0.829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>2</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.035</td>\n",
       "      <td>13.086</td>\n",
       "      <td>9.192</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.241</td>\n",
       "      <td>1.759</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DE</td>\n",
       "      <td>UCB</td>\n",
       "      <td>6</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.037</td>\n",
       "      <td>33.979</td>\n",
       "      <td>26.015</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.477</td>\n",
       "      <td>1.633</td>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>GP</td>\n",
       "      <td>EI</td>\n",
       "      <td>2</td>\n",
       "      <td>1.145</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.038</td>\n",
       "      <td>13.433</td>\n",
       "      <td>9.261</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>1.782</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>DE</td>\n",
       "      <td>EI</td>\n",
       "      <td>8</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.038</td>\n",
       "      <td>18.205</td>\n",
       "      <td>14.976</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>1.304</td>\n",
       "      <td>0.683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>GP</td>\n",
       "      <td>TS</td>\n",
       "      <td>3</td>\n",
       "      <td>1.016</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.040</td>\n",
       "      <td>63.027</td>\n",
       "      <td>42.443</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.712</td>\n",
       "      <td>1.168</td>\n",
       "      <td>0.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>1</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.044</td>\n",
       "      <td>32.999</td>\n",
       "      <td>16.873</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>1.766</td>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>DE</td>\n",
       "      <td>TS</td>\n",
       "      <td>2</td>\n",
       "      <td>1.037</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.045</td>\n",
       "      <td>15.359</td>\n",
       "      <td>12.167</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>1.868</td>\n",
       "      <td>1.168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>DE</td>\n",
       "      <td>EI</td>\n",
       "      <td>2</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.046</td>\n",
       "      <td>15.454</td>\n",
       "      <td>12.058</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>2.019</td>\n",
       "      <td>1.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>GP</td>\n",
       "      <td>EI</td>\n",
       "      <td>9</td>\n",
       "      <td>1.100</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.046</td>\n",
       "      <td>30.037</td>\n",
       "      <td>16.888</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.304</td>\n",
       "      <td>1.359</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>10</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.047</td>\n",
       "      <td>11.174</td>\n",
       "      <td>9.121</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>1.609</td>\n",
       "      <td>1.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>GP</td>\n",
       "      <td>TS</td>\n",
       "      <td>2</td>\n",
       "      <td>1.067</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.047</td>\n",
       "      <td>18.175</td>\n",
       "      <td>14.686</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.452</td>\n",
       "      <td>1.760</td>\n",
       "      <td>1.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>DE</td>\n",
       "      <td>TS</td>\n",
       "      <td>9</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.048</td>\n",
       "      <td>31.703</td>\n",
       "      <td>22.588</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.450</td>\n",
       "      <td>1.413</td>\n",
       "      <td>1.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>DE</td>\n",
       "      <td>UCB</td>\n",
       "      <td>10</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.052</td>\n",
       "      <td>14.557</td>\n",
       "      <td>12.827</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.300</td>\n",
       "      <td>1.810</td>\n",
       "      <td>1.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>GP</td>\n",
       "      <td>EI</td>\n",
       "      <td>10</td>\n",
       "      <td>1.130</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.052</td>\n",
       "      <td>11.959</td>\n",
       "      <td>10.020</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.123</td>\n",
       "      <td>1.906</td>\n",
       "      <td>1.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>DE</td>\n",
       "      <td>EI</td>\n",
       "      <td>3</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.053</td>\n",
       "      <td>61.490</td>\n",
       "      <td>41.269</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.609</td>\n",
       "      <td>1.240</td>\n",
       "      <td>0.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GP</td>\n",
       "      <td>UCB</td>\n",
       "      <td>4</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.054</td>\n",
       "      <td>16.881</td>\n",
       "      <td>13.072</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.118</td>\n",
       "      <td>1.841</td>\n",
       "      <td>1.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DE</td>\n",
       "      <td>UCB</td>\n",
       "      <td>2</td>\n",
       "      <td>0.987</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.054</td>\n",
       "      <td>15.570</td>\n",
       "      <td>12.457</td>\n",
       "      <td>0.034</td>\n",
       "      <td>-0.287</td>\n",
       "      <td>2.024</td>\n",
       "      <td>1.304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RF</td>\n",
       "      <td>UCB</td>\n",
       "      <td>7</td>\n",
       "      <td>1.031</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.056</td>\n",
       "      <td>27.484</td>\n",
       "      <td>23.724</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.568</td>\n",
       "      <td>1.560</td>\n",
       "      <td>0.741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RF</td>\n",
       "      <td>UCB</td>\n",
       "      <td>5</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.056</td>\n",
       "      <td>49.175</td>\n",
       "      <td>41.023</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.661</td>\n",
       "      <td>1.186</td>\n",
       "      <td>0.646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>GP</td>\n",
       "      <td>TS</td>\n",
       "      <td>9</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.056</td>\n",
       "      <td>48.943</td>\n",
       "      <td>38.024</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.537</td>\n",
       "      <td>1.431</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>GP</td>\n",
       "      <td>TS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.047</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.059</td>\n",
       "      <td>15.323</td>\n",
       "      <td>13.840</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>1.691</td>\n",
       "      <td>1.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>DE</td>\n",
       "      <td>TS</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.060</td>\n",
       "      <td>38.420</td>\n",
       "      <td>24.283</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>1.714</td>\n",
       "      <td>1.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>GP</td>\n",
       "      <td>EI</td>\n",
       "      <td>1</td>\n",
       "      <td>1.173</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.060</td>\n",
       "      <td>33.334</td>\n",
       "      <td>17.340</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.311</td>\n",
       "      <td>1.814</td>\n",
       "      <td>0.855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>DE</td>\n",
       "      <td>UCB</td>\n",
       "      <td>9</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.061</td>\n",
       "      <td>32.949</td>\n",
       "      <td>21.928</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.456</td>\n",
       "      <td>1.463</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>DE</td>\n",
       "      <td>EI</td>\n",
       "      <td>10</td>\n",
       "      <td>1.011</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.061</td>\n",
       "      <td>15.263</td>\n",
       "      <td>13.438</td>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.257</td>\n",
       "      <td>1.738</td>\n",
       "      <td>1.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>DE</td>\n",
       "      <td>EI</td>\n",
       "      <td>1</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.061</td>\n",
       "      <td>38.174</td>\n",
       "      <td>25.121</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.342</td>\n",
       "      <td>1.752</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>DE</td>\n",
       "      <td>EI</td>\n",
       "      <td>9</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.063</td>\n",
       "      <td>33.996</td>\n",
       "      <td>24.950</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>1.388</td>\n",
       "      <td>0.954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>DE</td>\n",
       "      <td>TS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.058</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.063</td>\n",
       "      <td>15.124</td>\n",
       "      <td>13.672</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.259</td>\n",
       "      <td>1.888</td>\n",
       "      <td>1.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>GP</td>\n",
       "      <td>EI</td>\n",
       "      <td>4</td>\n",
       "      <td>1.178</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.064</td>\n",
       "      <td>17.248</td>\n",
       "      <td>13.263</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>1.925</td>\n",
       "      <td>1.129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DE</td>\n",
       "      <td>UCB</td>\n",
       "      <td>3</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.065</td>\n",
       "      <td>62.255</td>\n",
       "      <td>42.243</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.634</td>\n",
       "      <td>1.229</td>\n",
       "      <td>0.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>RF</td>\n",
       "      <td>UCB</td>\n",
       "      <td>10</td>\n",
       "      <td>1.075</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.065</td>\n",
       "      <td>14.956</td>\n",
       "      <td>13.768</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.227</td>\n",
       "      <td>1.786</td>\n",
       "      <td>1.497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE</td>\n",
       "      <td>UCB</td>\n",
       "      <td>1</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.067</td>\n",
       "      <td>37.016</td>\n",
       "      <td>23.216</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.349</td>\n",
       "      <td>1.713</td>\n",
       "      <td>1.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>DE</td>\n",
       "      <td>EI</td>\n",
       "      <td>4</td>\n",
       "      <td>1.036</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.069</td>\n",
       "      <td>22.376</td>\n",
       "      <td>19.564</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.199</td>\n",
       "      <td>1.890</td>\n",
       "      <td>1.410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>DE</td>\n",
       "      <td>TS</td>\n",
       "      <td>4</td>\n",
       "      <td>1.078</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.070</td>\n",
       "      <td>21.719</td>\n",
       "      <td>19.015</td>\n",
       "      <td>0.040</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>1.912</td>\n",
       "      <td>1.488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RF</td>\n",
       "      <td>UCB</td>\n",
       "      <td>8</td>\n",
       "      <td>1.025</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.070</td>\n",
       "      <td>21.666</td>\n",
       "      <td>20.067</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.506</td>\n",
       "      <td>1.349</td>\n",
       "      <td>1.207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>DE</td>\n",
       "      <td>TS</td>\n",
       "      <td>3</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.341</td>\n",
       "      <td>0.072</td>\n",
       "      <td>64.194</td>\n",
       "      <td>44.174</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.575</td>\n",
       "      <td>1.226</td>\n",
       "      <td>0.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>RF</td>\n",
       "      <td>EI</td>\n",
       "      <td>2</td>\n",
       "      <td>1.098</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.072</td>\n",
       "      <td>20.035</td>\n",
       "      <td>17.576</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.354</td>\n",
       "      <td>1.924</td>\n",
       "      <td>1.555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RF</td>\n",
       "      <td>UCB</td>\n",
       "      <td>2</td>\n",
       "      <td>1.064</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.074</td>\n",
       "      <td>20.214</td>\n",
       "      <td>17.892</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>1.869</td>\n",
       "      <td>1.433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>RF</td>\n",
       "      <td>EI</td>\n",
       "      <td>7</td>\n",
       "      <td>1.072</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.075</td>\n",
       "      <td>28.289</td>\n",
       "      <td>25.631</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.569</td>\n",
       "      <td>1.499</td>\n",
       "      <td>1.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DE</td>\n",
       "      <td>UCB</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.077</td>\n",
       "      <td>21.720</td>\n",
       "      <td>19.372</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.226</td>\n",
       "      <td>1.883</td>\n",
       "      <td>1.511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>GP</td>\n",
       "      <td>TS</td>\n",
       "      <td>4</td>\n",
       "      <td>1.111</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.078</td>\n",
       "      <td>26.444</td>\n",
       "      <td>23.584</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>1.916</td>\n",
       "      <td>1.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>RF</td>\n",
       "      <td>EI</td>\n",
       "      <td>8</td>\n",
       "      <td>1.065</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.084</td>\n",
       "      <td>22.611</td>\n",
       "      <td>21.404</td>\n",
       "      <td>0.026</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>1.311</td>\n",
       "      <td>1.293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>RF</td>\n",
       "      <td>EI</td>\n",
       "      <td>5</td>\n",
       "      <td>1.030</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.084</td>\n",
       "      <td>52.328</td>\n",
       "      <td>44.512</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.651</td>\n",
       "      <td>1.280</td>\n",
       "      <td>0.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>RF</td>\n",
       "      <td>EI</td>\n",
       "      <td>10</td>\n",
       "      <td>1.121</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.088</td>\n",
       "      <td>16.956</td>\n",
       "      <td>15.988</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.224</td>\n",
       "      <td>1.788</td>\n",
       "      <td>1.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RF</td>\n",
       "      <td>TS</td>\n",
       "      <td>2</td>\n",
       "      <td>1.225</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.091</td>\n",
       "      <td>24.831</td>\n",
       "      <td>22.911</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.396</td>\n",
       "      <td>1.920</td>\n",
       "      <td>1.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>RF</td>\n",
       "      <td>UCB</td>\n",
       "      <td>9</td>\n",
       "      <td>1.041</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.093</td>\n",
       "      <td>45.083</td>\n",
       "      <td>37.596</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>1.503</td>\n",
       "      <td>1.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RF</td>\n",
       "      <td>UCB</td>\n",
       "      <td>3</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.102</td>\n",
       "      <td>72.451</td>\n",
       "      <td>57.570</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.563</td>\n",
       "      <td>1.314</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RF</td>\n",
       "      <td>UCB</td>\n",
       "      <td>4</td>\n",
       "      <td>1.084</td>\n",
       "      <td>0.138</td>\n",
       "      <td>0.105</td>\n",
       "      <td>22.384</td>\n",
       "      <td>20.704</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>2.031</td>\n",
       "      <td>1.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>GP</td>\n",
       "      <td>TS</td>\n",
       "      <td>1</td>\n",
       "      <td>1.076</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.107</td>\n",
       "      <td>68.059</td>\n",
       "      <td>59.331</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.447</td>\n",
       "      <td>1.886</td>\n",
       "      <td>0.881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>UCB</td>\n",
       "      <td>1</td>\n",
       "      <td>1.070</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.108</td>\n",
       "      <td>52.998</td>\n",
       "      <td>43.285</td>\n",
       "      <td>0.023</td>\n",
       "      <td>-0.249</td>\n",
       "      <td>1.778</td>\n",
       "      <td>1.402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>RF</td>\n",
       "      <td>EI</td>\n",
       "      <td>9</td>\n",
       "      <td>1.083</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.109</td>\n",
       "      <td>41.920</td>\n",
       "      <td>35.131</td>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.453</td>\n",
       "      <td>1.301</td>\n",
       "      <td>1.329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>RF</td>\n",
       "      <td>TS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.250</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.116</td>\n",
       "      <td>22.319</td>\n",
       "      <td>21.391</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.363</td>\n",
       "      <td>1.837</td>\n",
       "      <td>1.767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>RF</td>\n",
       "      <td>EI</td>\n",
       "      <td>3</td>\n",
       "      <td>1.044</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.123</td>\n",
       "      <td>76.621</td>\n",
       "      <td>62.757</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.533</td>\n",
       "      <td>1.306</td>\n",
       "      <td>0.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>RF</td>\n",
       "      <td>EI</td>\n",
       "      <td>4</td>\n",
       "      <td>1.127</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.133</td>\n",
       "      <td>26.417</td>\n",
       "      <td>25.854</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>2.036</td>\n",
       "      <td>1.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>RF</td>\n",
       "      <td>TS</td>\n",
       "      <td>8</td>\n",
       "      <td>1.237</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.160</td>\n",
       "      <td>31.664</td>\n",
       "      <td>31.788</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.521</td>\n",
       "      <td>1.701</td>\n",
       "      <td>1.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>RF</td>\n",
       "      <td>TS</td>\n",
       "      <td>7</td>\n",
       "      <td>1.233</td>\n",
       "      <td>0.193</td>\n",
       "      <td>0.172</td>\n",
       "      <td>38.362</td>\n",
       "      <td>37.294</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.632</td>\n",
       "      <td>1.460</td>\n",
       "      <td>1.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>RF</td>\n",
       "      <td>TS</td>\n",
       "      <td>4</td>\n",
       "      <td>1.252</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.193</td>\n",
       "      <td>31.040</td>\n",
       "      <td>31.148</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.210</td>\n",
       "      <td>2.015</td>\n",
       "      <td>2.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>RF</td>\n",
       "      <td>EI</td>\n",
       "      <td>1</td>\n",
       "      <td>1.117</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.200</td>\n",
       "      <td>59.826</td>\n",
       "      <td>53.690</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>1.831</td>\n",
       "      <td>1.605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>GP</td>\n",
       "      <td>RS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.327</td>\n",
       "      <td>0.214</td>\n",
       "      <td>0.202</td>\n",
       "      <td>28.945</td>\n",
       "      <td>27.916</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>RF</td>\n",
       "      <td>RS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.332</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.203</td>\n",
       "      <td>27.939</td>\n",
       "      <td>27.157</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.416</td>\n",
       "      <td>1.976</td>\n",
       "      <td>2.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RF</td>\n",
       "      <td>UCB</td>\n",
       "      <td>6</td>\n",
       "      <td>1.029</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.204</td>\n",
       "      <td>53.400</td>\n",
       "      <td>48.438</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>1.580</td>\n",
       "      <td>1.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>DE</td>\n",
       "      <td>RS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.328</td>\n",
       "      <td>0.221</td>\n",
       "      <td>0.213</td>\n",
       "      <td>28.742</td>\n",
       "      <td>27.960</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.063</td>\n",
       "      <td>2.186</td>\n",
       "      <td>1.903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>BNN</td>\n",
       "      <td>RS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.334</td>\n",
       "      <td>0.226</td>\n",
       "      <td>0.216</td>\n",
       "      <td>29.852</td>\n",
       "      <td>28.898</td>\n",
       "      <td>0.090</td>\n",
       "      <td>1.237</td>\n",
       "      <td>1.988</td>\n",
       "      <td>1.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BNN</td>\n",
       "      <td>UCB</td>\n",
       "      <td>8</td>\n",
       "      <td>1.170</td>\n",
       "      <td>0.261</td>\n",
       "      <td>0.236</td>\n",
       "      <td>38.226</td>\n",
       "      <td>36.169</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.858</td>\n",
       "      <td>1.744</td>\n",
       "      <td>1.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>GP</td>\n",
       "      <td>RS</td>\n",
       "      <td>2</td>\n",
       "      <td>1.328</td>\n",
       "      <td>0.249</td>\n",
       "      <td>0.238</td>\n",
       "      <td>35.896</td>\n",
       "      <td>34.983</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>2.105</td>\n",
       "      <td>2.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>RF</td>\n",
       "      <td>RS</td>\n",
       "      <td>2</td>\n",
       "      <td>1.330</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.239</td>\n",
       "      <td>36.294</td>\n",
       "      <td>35.184</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>1.921</td>\n",
       "      <td>1.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>DE</td>\n",
       "      <td>RS</td>\n",
       "      <td>2</td>\n",
       "      <td>1.329</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.240</td>\n",
       "      <td>36.637</td>\n",
       "      <td>35.648</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.126</td>\n",
       "      <td>1.998</td>\n",
       "      <td>1.983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>RF</td>\n",
       "      <td>EI</td>\n",
       "      <td>6</td>\n",
       "      <td>1.066</td>\n",
       "      <td>0.292</td>\n",
       "      <td>0.242</td>\n",
       "      <td>64.353</td>\n",
       "      <td>60.628</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.483</td>\n",
       "      <td>1.579</td>\n",
       "      <td>1.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>BNN</td>\n",
       "      <td>TS</td>\n",
       "      <td>10</td>\n",
       "      <td>1.332</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.247</td>\n",
       "      <td>32.421</td>\n",
       "      <td>31.516</td>\n",
       "      <td>0.092</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2.227</td>\n",
       "      <td>1.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BNN</td>\n",
       "      <td>UCB</td>\n",
       "      <td>10</td>\n",
       "      <td>1.196</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.250</td>\n",
       "      <td>31.759</td>\n",
       "      <td>30.448</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.870</td>\n",
       "      <td>2.211</td>\n",
       "      <td>1.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>BNN</td>\n",
       "      <td>RS</td>\n",
       "      <td>2</td>\n",
       "      <td>1.327</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.258</td>\n",
       "      <td>35.056</td>\n",
       "      <td>34.145</td>\n",
       "      <td>0.091</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2.071</td>\n",
       "      <td>1.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BNN</td>\n",
       "      <td>UCB</td>\n",
       "      <td>1</td>\n",
       "      <td>1.188</td>\n",
       "      <td>0.421</td>\n",
       "      <td>0.276</td>\n",
       "      <td>59.704</td>\n",
       "      <td>50.079</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.806</td>\n",
       "      <td>2.066</td>\n",
       "      <td>1.782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>RF</td>\n",
       "      <td>RS</td>\n",
       "      <td>8</td>\n",
       "      <td>1.332</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.277</td>\n",
       "      <td>41.521</td>\n",
       "      <td>41.758</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.582</td>\n",
       "      <td>1.787</td>\n",
       "      <td>1.676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BNN</td>\n",
       "      <td>UCB</td>\n",
       "      <td>4</td>\n",
       "      <td>1.213</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0.280</td>\n",
       "      <td>38.990</td>\n",
       "      <td>36.810</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.811</td>\n",
       "      <td>2.087</td>\n",
       "      <td>2.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>GP</td>\n",
       "      <td>RS</td>\n",
       "      <td>4</td>\n",
       "      <td>1.328</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.286</td>\n",
       "      <td>39.826</td>\n",
       "      <td>39.968</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>2.026</td>\n",
       "      <td>2.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>BNN</td>\n",
       "      <td>RS</td>\n",
       "      <td>4</td>\n",
       "      <td>1.327</td>\n",
       "      <td>0.286</td>\n",
       "      <td>0.287</td>\n",
       "      <td>39.764</td>\n",
       "      <td>40.006</td>\n",
       "      <td>0.105</td>\n",
       "      <td>1.239</td>\n",
       "      <td>1.905</td>\n",
       "      <td>2.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>DE</td>\n",
       "      <td>RS</td>\n",
       "      <td>4</td>\n",
       "      <td>1.329</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.288</td>\n",
       "      <td>38.579</td>\n",
       "      <td>38.821</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.010</td>\n",
       "      <td>2.031</td>\n",
       "      <td>2.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>RF</td>\n",
       "      <td>RS</td>\n",
       "      <td>4</td>\n",
       "      <td>1.330</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.296</td>\n",
       "      <td>40.419</td>\n",
       "      <td>40.659</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.265</td>\n",
       "      <td>1.882</td>\n",
       "      <td>2.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BNN</td>\n",
       "      <td>UCB</td>\n",
       "      <td>2</td>\n",
       "      <td>1.174</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.297</td>\n",
       "      <td>40.292</td>\n",
       "      <td>38.619</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.923</td>\n",
       "      <td>2.045</td>\n",
       "      <td>1.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BNN</td>\n",
       "      <td>TS</td>\n",
       "      <td>2</td>\n",
       "      <td>1.315</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.312</td>\n",
       "      <td>41.396</td>\n",
       "      <td>40.418</td>\n",
       "      <td>0.094</td>\n",
       "      <td>1.060</td>\n",
       "      <td>1.973</td>\n",
       "      <td>2.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>BNN</td>\n",
       "      <td>TS</td>\n",
       "      <td>8</td>\n",
       "      <td>1.304</td>\n",
       "      <td>0.336</td>\n",
       "      <td>0.324</td>\n",
       "      <td>48.395</td>\n",
       "      <td>47.840</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.940</td>\n",
       "      <td>1.725</td>\n",
       "      <td>1.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>RF</td>\n",
       "      <td>RS</td>\n",
       "      <td>7</td>\n",
       "      <td>1.332</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.324</td>\n",
       "      <td>48.757</td>\n",
       "      <td>47.867</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>1.600</td>\n",
       "      <td>1.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>BNN</td>\n",
       "      <td>RS</td>\n",
       "      <td>8</td>\n",
       "      <td>1.334</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.330</td>\n",
       "      <td>46.295</td>\n",
       "      <td>46.694</td>\n",
       "      <td>0.076</td>\n",
       "      <td>1.190</td>\n",
       "      <td>1.615</td>\n",
       "      <td>1.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>BNN</td>\n",
       "      <td>RS</td>\n",
       "      <td>7</td>\n",
       "      <td>1.334</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.331</td>\n",
       "      <td>45.756</td>\n",
       "      <td>44.866</td>\n",
       "      <td>0.078</td>\n",
       "      <td>1.211</td>\n",
       "      <td>1.393</td>\n",
       "      <td>1.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>GP</td>\n",
       "      <td>RS</td>\n",
       "      <td>8</td>\n",
       "      <td>1.327</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.331</td>\n",
       "      <td>47.429</td>\n",
       "      <td>47.828</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>1.690</td>\n",
       "      <td>1.780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>RF</td>\n",
       "      <td>TS</td>\n",
       "      <td>9</td>\n",
       "      <td>1.239</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.336</td>\n",
       "      <td>60.760</td>\n",
       "      <td>55.160</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.482</td>\n",
       "      <td>1.446</td>\n",
       "      <td>1.324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>DE</td>\n",
       "      <td>RS</td>\n",
       "      <td>7</td>\n",
       "      <td>1.328</td>\n",
       "      <td>0.352</td>\n",
       "      <td>0.343</td>\n",
       "      <td>48.990</td>\n",
       "      <td>48.100</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>1.633</td>\n",
       "      <td>1.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>BNN</td>\n",
       "      <td>TS</td>\n",
       "      <td>4</td>\n",
       "      <td>1.349</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.343</td>\n",
       "      <td>45.949</td>\n",
       "      <td>44.841</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.986</td>\n",
       "      <td>2.345</td>\n",
       "      <td>2.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>10</td>\n",
       "      <td>1.288</td>\n",
       "      <td>0.361</td>\n",
       "      <td>0.347</td>\n",
       "      <td>38.923</td>\n",
       "      <td>37.703</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.682</td>\n",
       "      <td>2.306</td>\n",
       "      <td>2.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>GP</td>\n",
       "      <td>RS</td>\n",
       "      <td>7</td>\n",
       "      <td>1.327</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.354</td>\n",
       "      <td>49.864</td>\n",
       "      <td>48.944</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>1.618</td>\n",
       "      <td>1.547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>DE</td>\n",
       "      <td>RS</td>\n",
       "      <td>8</td>\n",
       "      <td>1.328</td>\n",
       "      <td>0.351</td>\n",
       "      <td>0.355</td>\n",
       "      <td>45.937</td>\n",
       "      <td>46.335</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.095</td>\n",
       "      <td>1.650</td>\n",
       "      <td>1.677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>RF</td>\n",
       "      <td>TS</td>\n",
       "      <td>6</td>\n",
       "      <td>1.217</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.376</td>\n",
       "      <td>62.499</td>\n",
       "      <td>59.095</td>\n",
       "      <td>0.016</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>1.519</td>\n",
       "      <td>1.366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>RF</td>\n",
       "      <td>TS</td>\n",
       "      <td>5</td>\n",
       "      <td>1.228</td>\n",
       "      <td>0.443</td>\n",
       "      <td>0.400</td>\n",
       "      <td>82.498</td>\n",
       "      <td>80.624</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.659</td>\n",
       "      <td>1.430</td>\n",
       "      <td>1.225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BNN</td>\n",
       "      <td>UCB</td>\n",
       "      <td>6</td>\n",
       "      <td>1.209</td>\n",
       "      <td>0.478</td>\n",
       "      <td>0.423</td>\n",
       "      <td>72.652</td>\n",
       "      <td>68.151</td>\n",
       "      <td>0.091</td>\n",
       "      <td>0.818</td>\n",
       "      <td>1.861</td>\n",
       "      <td>1.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BNN</td>\n",
       "      <td>UCB</td>\n",
       "      <td>7</td>\n",
       "      <td>1.199</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.443</td>\n",
       "      <td>58.063</td>\n",
       "      <td>57.037</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.804</td>\n",
       "      <td>1.866</td>\n",
       "      <td>1.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>2</td>\n",
       "      <td>1.315</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.460</td>\n",
       "      <td>52.814</td>\n",
       "      <td>51.579</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.813</td>\n",
       "      <td>2.148</td>\n",
       "      <td>2.249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>4</td>\n",
       "      <td>1.353</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.463</td>\n",
       "      <td>53.000</td>\n",
       "      <td>51.695</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.607</td>\n",
       "      <td>2.295</td>\n",
       "      <td>2.258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>GP</td>\n",
       "      <td>RS</td>\n",
       "      <td>6</td>\n",
       "      <td>1.327</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.467</td>\n",
       "      <td>70.862</td>\n",
       "      <td>67.531</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>1.518</td>\n",
       "      <td>1.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BNN</td>\n",
       "      <td>UCB</td>\n",
       "      <td>9</td>\n",
       "      <td>1.233</td>\n",
       "      <td>0.526</td>\n",
       "      <td>0.474</td>\n",
       "      <td>69.959</td>\n",
       "      <td>64.927</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.865</td>\n",
       "      <td>1.839</td>\n",
       "      <td>1.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>RF</td>\n",
       "      <td>TS</td>\n",
       "      <td>3</td>\n",
       "      <td>1.228</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.485</td>\n",
       "      <td>105.315</td>\n",
       "      <td>100.376</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.553</td>\n",
       "      <td>1.287</td>\n",
       "      <td>1.240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>RF</td>\n",
       "      <td>RS</td>\n",
       "      <td>9</td>\n",
       "      <td>1.332</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.515</td>\n",
       "      <td>75.734</td>\n",
       "      <td>70.584</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.556</td>\n",
       "      <td>1.581</td>\n",
       "      <td>1.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>RF</td>\n",
       "      <td>RS</td>\n",
       "      <td>6</td>\n",
       "      <td>1.332</td>\n",
       "      <td>0.551</td>\n",
       "      <td>0.522</td>\n",
       "      <td>84.251</td>\n",
       "      <td>81.321</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.623</td>\n",
       "      <td>1.523</td>\n",
       "      <td>1.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>BNN</td>\n",
       "      <td>TS</td>\n",
       "      <td>7</td>\n",
       "      <td>1.335</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.545</td>\n",
       "      <td>67.346</td>\n",
       "      <td>66.456</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.943</td>\n",
       "      <td>1.804</td>\n",
       "      <td>1.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>RF</td>\n",
       "      <td>TS</td>\n",
       "      <td>1</td>\n",
       "      <td>1.251</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.569</td>\n",
       "      <td>82.941</td>\n",
       "      <td>80.350</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>1.900</td>\n",
       "      <td>1.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>8</td>\n",
       "      <td>1.344</td>\n",
       "      <td>0.592</td>\n",
       "      <td>0.582</td>\n",
       "      <td>65.476</td>\n",
       "      <td>65.060</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.601</td>\n",
       "      <td>1.999</td>\n",
       "      <td>1.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>GP</td>\n",
       "      <td>RS</td>\n",
       "      <td>9</td>\n",
       "      <td>1.327</td>\n",
       "      <td>0.640</td>\n",
       "      <td>0.586</td>\n",
       "      <td>84.784</td>\n",
       "      <td>79.525</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.252</td>\n",
       "      <td>1.584</td>\n",
       "      <td>1.606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>BNN</td>\n",
       "      <td>RS</td>\n",
       "      <td>9</td>\n",
       "      <td>1.334</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.608</td>\n",
       "      <td>87.515</td>\n",
       "      <td>82.514</td>\n",
       "      <td>0.083</td>\n",
       "      <td>1.234</td>\n",
       "      <td>1.664</td>\n",
       "      <td>1.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>DE</td>\n",
       "      <td>RS</td>\n",
       "      <td>9</td>\n",
       "      <td>1.328</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.637</td>\n",
       "      <td>86.063</td>\n",
       "      <td>81.023</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.025</td>\n",
       "      <td>1.570</td>\n",
       "      <td>1.725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>BNN</td>\n",
       "      <td>TS</td>\n",
       "      <td>1</td>\n",
       "      <td>1.335</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.678</td>\n",
       "      <td>93.539</td>\n",
       "      <td>85.336</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.955</td>\n",
       "      <td>1.985</td>\n",
       "      <td>2.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BNN</td>\n",
       "      <td>UCB</td>\n",
       "      <td>5</td>\n",
       "      <td>1.201</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.700</td>\n",
       "      <td>99.669</td>\n",
       "      <td>96.659</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.840</td>\n",
       "      <td>1.613</td>\n",
       "      <td>1.201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>7</td>\n",
       "      <td>1.289</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.701</td>\n",
       "      <td>76.253</td>\n",
       "      <td>74.637</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.512</td>\n",
       "      <td>2.175</td>\n",
       "      <td>1.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>BNN</td>\n",
       "      <td>RS</td>\n",
       "      <td>6</td>\n",
       "      <td>1.334</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.702</td>\n",
       "      <td>94.095</td>\n",
       "      <td>90.980</td>\n",
       "      <td>0.082</td>\n",
       "      <td>1.256</td>\n",
       "      <td>1.587</td>\n",
       "      <td>1.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>DE</td>\n",
       "      <td>RS</td>\n",
       "      <td>1</td>\n",
       "      <td>1.329</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.708</td>\n",
       "      <td>91.440</td>\n",
       "      <td>88.944</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.891</td>\n",
       "      <td>1.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>GP</td>\n",
       "      <td>RS</td>\n",
       "      <td>1</td>\n",
       "      <td>1.328</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.711</td>\n",
       "      <td>92.046</td>\n",
       "      <td>89.079</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.290</td>\n",
       "      <td>1.902</td>\n",
       "      <td>1.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>BNN</td>\n",
       "      <td>RS</td>\n",
       "      <td>1</td>\n",
       "      <td>1.327</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.715</td>\n",
       "      <td>93.881</td>\n",
       "      <td>91.379</td>\n",
       "      <td>0.094</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2.008</td>\n",
       "      <td>1.866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>RF</td>\n",
       "      <td>RS</td>\n",
       "      <td>1</td>\n",
       "      <td>1.330</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.729</td>\n",
       "      <td>93.477</td>\n",
       "      <td>90.936</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>1.971</td>\n",
       "      <td>1.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>DE</td>\n",
       "      <td>RS</td>\n",
       "      <td>6</td>\n",
       "      <td>1.328</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.750</td>\n",
       "      <td>94.159</td>\n",
       "      <td>91.229</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.047</td>\n",
       "      <td>1.758</td>\n",
       "      <td>1.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>BNN</td>\n",
       "      <td>RS</td>\n",
       "      <td>5</td>\n",
       "      <td>1.327</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.764</td>\n",
       "      <td>98.153</td>\n",
       "      <td>97.531</td>\n",
       "      <td>0.077</td>\n",
       "      <td>1.183</td>\n",
       "      <td>1.491</td>\n",
       "      <td>1.443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>BNN</td>\n",
       "      <td>TS</td>\n",
       "      <td>6</td>\n",
       "      <td>1.329</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.780</td>\n",
       "      <td>98.679</td>\n",
       "      <td>95.349</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.923</td>\n",
       "      <td>1.895</td>\n",
       "      <td>1.747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>GP</td>\n",
       "      <td>RS</td>\n",
       "      <td>5</td>\n",
       "      <td>1.328</td>\n",
       "      <td>0.795</td>\n",
       "      <td>0.789</td>\n",
       "      <td>106.718</td>\n",
       "      <td>106.243</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.153</td>\n",
       "      <td>1.428</td>\n",
       "      <td>1.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>BNN</td>\n",
       "      <td>TS</td>\n",
       "      <td>9</td>\n",
       "      <td>1.349</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.821</td>\n",
       "      <td>97.454</td>\n",
       "      <td>92.487</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.758</td>\n",
       "      <td>1.834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>1</td>\n",
       "      <td>1.347</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.832</td>\n",
       "      <td>100.252</td>\n",
       "      <td>92.373</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.506</td>\n",
       "      <td>2.225</td>\n",
       "      <td>2.123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>DE</td>\n",
       "      <td>RS</td>\n",
       "      <td>5</td>\n",
       "      <td>1.329</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.878</td>\n",
       "      <td>111.867</td>\n",
       "      <td>111.405</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.056</td>\n",
       "      <td>1.607</td>\n",
       "      <td>1.575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>RF</td>\n",
       "      <td>RS</td>\n",
       "      <td>5</td>\n",
       "      <td>1.330</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.884</td>\n",
       "      <td>108.347</td>\n",
       "      <td>107.751</td>\n",
       "      <td>0.005</td>\n",
       "      <td>-0.657</td>\n",
       "      <td>1.472</td>\n",
       "      <td>1.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>DE</td>\n",
       "      <td>RS</td>\n",
       "      <td>3</td>\n",
       "      <td>1.329</td>\n",
       "      <td>1.018</td>\n",
       "      <td>0.916</td>\n",
       "      <td>137.415</td>\n",
       "      <td>129.971</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>1.461</td>\n",
       "      <td>1.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>GP</td>\n",
       "      <td>RS</td>\n",
       "      <td>3</td>\n",
       "      <td>1.328</td>\n",
       "      <td>1.007</td>\n",
       "      <td>0.975</td>\n",
       "      <td>133.152</td>\n",
       "      <td>130.062</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>1.446</td>\n",
       "      <td>1.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>9</td>\n",
       "      <td>1.373</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0.977</td>\n",
       "      <td>107.715</td>\n",
       "      <td>102.748</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.577</td>\n",
       "      <td>1.919</td>\n",
       "      <td>1.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>6</td>\n",
       "      <td>1.359</td>\n",
       "      <td>1.034</td>\n",
       "      <td>0.981</td>\n",
       "      <td>111.421</td>\n",
       "      <td>107.543</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.502</td>\n",
       "      <td>2.051</td>\n",
       "      <td>1.827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BNN</td>\n",
       "      <td>UCB</td>\n",
       "      <td>3</td>\n",
       "      <td>1.237</td>\n",
       "      <td>1.078</td>\n",
       "      <td>1.014</td>\n",
       "      <td>137.942</td>\n",
       "      <td>132.900</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.816</td>\n",
       "      <td>1.678</td>\n",
       "      <td>1.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>RF</td>\n",
       "      <td>RS</td>\n",
       "      <td>3</td>\n",
       "      <td>1.330</td>\n",
       "      <td>1.053</td>\n",
       "      <td>1.021</td>\n",
       "      <td>139.366</td>\n",
       "      <td>136.237</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.552</td>\n",
       "      <td>1.452</td>\n",
       "      <td>1.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>BNN</td>\n",
       "      <td>RS</td>\n",
       "      <td>3</td>\n",
       "      <td>1.327</td>\n",
       "      <td>1.084</td>\n",
       "      <td>1.048</td>\n",
       "      <td>139.251</td>\n",
       "      <td>136.035</td>\n",
       "      <td>0.093</td>\n",
       "      <td>1.240</td>\n",
       "      <td>1.430</td>\n",
       "      <td>1.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>BNN</td>\n",
       "      <td>TS</td>\n",
       "      <td>5</td>\n",
       "      <td>1.312</td>\n",
       "      <td>1.083</td>\n",
       "      <td>1.051</td>\n",
       "      <td>122.103</td>\n",
       "      <td>119.577</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.969</td>\n",
       "      <td>1.609</td>\n",
       "      <td>1.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>BNN</td>\n",
       "      <td>TS</td>\n",
       "      <td>3</td>\n",
       "      <td>1.311</td>\n",
       "      <td>1.230</td>\n",
       "      <td>1.179</td>\n",
       "      <td>147.663</td>\n",
       "      <td>143.590</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.686</td>\n",
       "      <td>1.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>5</td>\n",
       "      <td>1.326</td>\n",
       "      <td>1.226</td>\n",
       "      <td>1.191</td>\n",
       "      <td>133.095</td>\n",
       "      <td>131.066</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.575</td>\n",
       "      <td>1.652</td>\n",
       "      <td>1.472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>BNN</td>\n",
       "      <td>EI</td>\n",
       "      <td>3</td>\n",
       "      <td>1.343</td>\n",
       "      <td>1.667</td>\n",
       "      <td>1.610</td>\n",
       "      <td>176.863</td>\n",
       "      <td>172.500</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.538</td>\n",
       "      <td>1.932</td>\n",
       "      <td>1.839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    surrogate acquisition  problem_idx  dist_nearest_train_mean  \\\n",
       "18         GP         UCB            5                    0.761   \n",
       "26         GP         UCB            7                    0.807   \n",
       "17         DE         UCB            5                    0.858   \n",
       "58         GP          TS            5                    0.952   \n",
       "97         DE          EI            5                    0.887   \n",
       "22         GP         UCB            6                    0.797   \n",
       "66         GP          TS            7                    0.973   \n",
       "98         GP          EI            5                    1.138   \n",
       "102        GP          EI            6                    1.093   \n",
       "57         DE          TS            5                    0.905   \n",
       "10         GP         UCB            3                    0.766   \n",
       "105        DE          EI            7                    0.924   \n",
       "62         GP          TS            6                    1.024   \n",
       "106        GP          EI            7                    1.115   \n",
       "29         DE         UCB            8                    0.895   \n",
       "69         DE          TS            8                    0.939   \n",
       "30         GP         UCB            8                    0.784   \n",
       "90         GP          EI            3                    1.190   \n",
       "34         GP         UCB            9                    0.767   \n",
       "25         DE         UCB            7                    0.898   \n",
       "70         GP          TS            8                    0.996   \n",
       "65         DE          TS            7                    0.945   \n",
       "110        GP          EI            8                    1.059   \n",
       "101        DE          EI            6                    0.925   \n",
       "61         DE          TS            6                    0.971   \n",
       "6          GP         UCB            2                    0.814   \n",
       "21         DE         UCB            6                    0.894   \n",
       "86         GP          EI            2                    1.145   \n",
       "109        DE          EI            8                    0.925   \n",
       "50         GP          TS            3                    1.016   \n",
       "2          GP         UCB            1                    0.835   \n",
       "45         DE          TS            2                    1.037   \n",
       "85         DE          EI            2                    1.009   \n",
       "114        GP          EI            9                    1.100   \n",
       "38         GP         UCB           10                    0.803   \n",
       "46         GP          TS            2                    1.067   \n",
       "73         DE          TS            9                    0.978   \n",
       "37         DE         UCB           10                    0.989   \n",
       "118        GP          EI           10                    1.130   \n",
       "89         DE          EI            3                    0.923   \n",
       "14         GP         UCB            4                    0.849   \n",
       "5          DE         UCB            2                    0.987   \n",
       "27         RF         UCB            7                    1.031   \n",
       "19         RF         UCB            5                    0.980   \n",
       "74         GP          TS            9                    0.992   \n",
       "78         GP          TS           10                    1.047   \n",
       "41         DE          TS            1                    1.011   \n",
       "82         GP          EI            1                    1.173   \n",
       "33         DE         UCB            9                    0.924   \n",
       "117        DE          EI           10                    1.011   \n",
       "81         DE          EI            1                    0.982   \n",
       "113        DE          EI            9                    0.949   \n",
       "77         DE          TS           10                    1.058   \n",
       "94         GP          EI            4                    1.178   \n",
       "9          DE         UCB            3                    0.898   \n",
       "39         RF         UCB           10                    1.075   \n",
       "1          DE         UCB            1                    0.931   \n",
       "93         DE          EI            4                    1.036   \n",
       "53         DE          TS            4                    1.078   \n",
       "31         RF         UCB            8                    1.025   \n",
       "49         DE          TS            3                    0.956   \n",
       "87         RF          EI            2                    1.098   \n",
       "7          RF         UCB            2                    1.064   \n",
       "107        RF          EI            7                    1.072   \n",
       "13         DE         UCB            4                    1.000   \n",
       "54         GP          TS            4                    1.111   \n",
       "111        RF          EI            8                    1.065   \n",
       "99         RF          EI            5                    1.030   \n",
       "119        RF          EI           10                    1.121   \n",
       "47         RF          TS            2                    1.225   \n",
       "35         RF         UCB            9                    1.041   \n",
       "11         RF         UCB            3                    0.998   \n",
       "15         RF         UCB            4                    1.084   \n",
       "42         GP          TS            1                    1.076   \n",
       "3          RF         UCB            1                    1.070   \n",
       "115        RF          EI            9                    1.083   \n",
       "79         RF          TS           10                    1.250   \n",
       "91         RF          EI            3                    1.044   \n",
       "95         RF          EI            4                    1.127   \n",
       "71         RF          TS            8                    1.237   \n",
       "67         RF          TS            7                    1.233   \n",
       "55         RF          TS            4                    1.252   \n",
       "83         RF          EI            1                    1.117   \n",
       "158        GP          RS           10                    1.327   \n",
       "159        RF          RS           10                    1.332   \n",
       "23         RF         UCB            6                    1.029   \n",
       "157        DE          RS           10                    1.328   \n",
       "156       BNN          RS           10                    1.334   \n",
       "28        BNN         UCB            8                    1.170   \n",
       "126        GP          RS            2                    1.328   \n",
       "127        RF          RS            2                    1.330   \n",
       "125        DE          RS            2                    1.329   \n",
       "103        RF          EI            6                    1.066   \n",
       "76        BNN          TS           10                    1.332   \n",
       "36        BNN         UCB           10                    1.196   \n",
       "124       BNN          RS            2                    1.327   \n",
       "0         BNN         UCB            1                    1.188   \n",
       "151        RF          RS            8                    1.332   \n",
       "12        BNN         UCB            4                    1.213   \n",
       "134        GP          RS            4                    1.328   \n",
       "132       BNN          RS            4                    1.327   \n",
       "133        DE          RS            4                    1.329   \n",
       "135        RF          RS            4                    1.330   \n",
       "4         BNN         UCB            2                    1.174   \n",
       "44        BNN          TS            2                    1.315   \n",
       "68        BNN          TS            8                    1.304   \n",
       "147        RF          RS            7                    1.332   \n",
       "148       BNN          RS            8                    1.334   \n",
       "144       BNN          RS            7                    1.334   \n",
       "150        GP          RS            8                    1.327   \n",
       "75         RF          TS            9                    1.239   \n",
       "145        DE          RS            7                    1.328   \n",
       "52        BNN          TS            4                    1.349   \n",
       "116       BNN          EI           10                    1.288   \n",
       "146        GP          RS            7                    1.327   \n",
       "149        DE          RS            8                    1.328   \n",
       "63         RF          TS            6                    1.217   \n",
       "59         RF          TS            5                    1.228   \n",
       "20        BNN         UCB            6                    1.209   \n",
       "24        BNN         UCB            7                    1.199   \n",
       "84        BNN          EI            2                    1.315   \n",
       "92        BNN          EI            4                    1.353   \n",
       "142        GP          RS            6                    1.327   \n",
       "32        BNN         UCB            9                    1.233   \n",
       "51         RF          TS            3                    1.228   \n",
       "155        RF          RS            9                    1.332   \n",
       "143        RF          RS            6                    1.332   \n",
       "64        BNN          TS            7                    1.335   \n",
       "43         RF          TS            1                    1.251   \n",
       "108       BNN          EI            8                    1.344   \n",
       "154        GP          RS            9                    1.327   \n",
       "152       BNN          RS            9                    1.334   \n",
       "153        DE          RS            9                    1.328   \n",
       "40        BNN          TS            1                    1.335   \n",
       "16        BNN         UCB            5                    1.201   \n",
       "104       BNN          EI            7                    1.289   \n",
       "140       BNN          RS            6                    1.334   \n",
       "121        DE          RS            1                    1.329   \n",
       "122        GP          RS            1                    1.328   \n",
       "120       BNN          RS            1                    1.327   \n",
       "123        RF          RS            1                    1.330   \n",
       "141        DE          RS            6                    1.328   \n",
       "136       BNN          RS            5                    1.327   \n",
       "60        BNN          TS            6                    1.329   \n",
       "138        GP          RS            5                    1.328   \n",
       "72        BNN          TS            9                    1.349   \n",
       "80        BNN          EI            1                    1.347   \n",
       "137        DE          RS            5                    1.329   \n",
       "139        RF          RS            5                    1.330   \n",
       "129        DE          RS            3                    1.329   \n",
       "130        GP          RS            3                    1.328   \n",
       "112       BNN          EI            9                    1.373   \n",
       "100       BNN          EI            6                    1.359   \n",
       "8         BNN         UCB            3                    1.237   \n",
       "131        RF          RS            3                    1.330   \n",
       "128       BNN          RS            3                    1.327   \n",
       "56        BNN          TS            5                    1.312   \n",
       "48        BNN          TS            3                    1.311   \n",
       "96        BNN          EI            5                    1.326   \n",
       "88        BNN          EI            3                    1.343   \n",
       "\n",
       "     inst_regret_test  inst_regret_pool  tot_regret_test  tot_regret_pool  \\\n",
       "18              0.195             0.009           32.015           15.899   \n",
       "26              0.104             0.009           16.106            9.442   \n",
       "17              0.196             0.013           40.310           27.731   \n",
       "58              0.197             0.015           49.548           37.507   \n",
       "97              0.200             0.017           41.177           28.918   \n",
       "22              0.123             0.017           24.558           15.272   \n",
       "66              0.106             0.018           23.813           18.917   \n",
       "98              0.199             0.019           30.359           14.299   \n",
       "102             0.123             0.019           23.994           14.839   \n",
       "57              0.200             0.020           41.451           28.908   \n",
       "10              0.299             0.020           44.191           19.891   \n",
       "105             0.108             0.020           20.733           15.744   \n",
       "62              0.130             0.020           54.272           46.382   \n",
       "106             0.112             0.022           17.381           10.378   \n",
       "29              0.076             0.026           18.906           15.624   \n",
       "69              0.076             0.027           18.974           15.459   \n",
       "30              0.071             0.027           12.803            8.998   \n",
       "90              0.304             0.028           44.283           19.967   \n",
       "34              0.177             0.028           29.694           16.050   \n",
       "25              0.107             0.029           21.107           15.519   \n",
       "70              0.077             0.030           25.484           22.632   \n",
       "65              0.096             0.030           20.337           16.009   \n",
       "110             0.081             0.032           13.592            9.701   \n",
       "101             0.138             0.033           32.708           25.079   \n",
       "61              0.140             0.035           36.406           29.163   \n",
       "6               0.090             0.035           13.086            9.192   \n",
       "21              0.136             0.037           33.979           26.015   \n",
       "86              0.091             0.038           13.433            9.261   \n",
       "109             0.083             0.038           18.205           14.976   \n",
       "50              0.315             0.040           63.027           42.443   \n",
       "2               0.225             0.044           32.999           16.873   \n",
       "45              0.093             0.045           15.359           12.167   \n",
       "85              0.094             0.046           15.454           12.058   \n",
       "114             0.190             0.046           30.037           16.888   \n",
       "38              0.070             0.047           11.174            9.121   \n",
       "46              0.098             0.047           18.175           14.686   \n",
       "73              0.192             0.048           31.703           22.588   \n",
       "37              0.078             0.052           14.557           12.827   \n",
       "118             0.076             0.052           11.959           10.020   \n",
       "89              0.328             0.053           61.490           41.269   \n",
       "14              0.111             0.054           16.881           13.072   \n",
       "5               0.094             0.054           15.570           12.457   \n",
       "27              0.127             0.056           27.484           23.724   \n",
       "19              0.219             0.056           49.175           41.023   \n",
       "74              0.199             0.056           48.943           38.024   \n",
       "78              0.078             0.059           15.323           13.840   \n",
       "41              0.234             0.060           38.420           24.283   \n",
       "82              0.236             0.060           33.334           17.340   \n",
       "33              0.205             0.061           32.949           21.928   \n",
       "117             0.086             0.061           15.263           13.438   \n",
       "81              0.234             0.061           38.174           25.121   \n",
       "113             0.206             0.063           33.996           24.950   \n",
       "77              0.082             0.063           15.124           13.672   \n",
       "94              0.119             0.064           17.248           13.263   \n",
       "9               0.339             0.065           62.255           42.243   \n",
       "39              0.082             0.065           14.956           13.768   \n",
       "1               0.233             0.067           37.016           23.216   \n",
       "93              0.120             0.069           22.376           19.564   \n",
       "53              0.121             0.070           21.719           19.015   \n",
       "31              0.106             0.070           21.666           20.067   \n",
       "49              0.341             0.072           64.194           44.174   \n",
       "87              0.110             0.072           20.035           17.576   \n",
       "7               0.111             0.074           20.214           17.892   \n",
       "107             0.127             0.075           28.289           25.631   \n",
       "13              0.120             0.077           21.720           19.372   \n",
       "54              0.133             0.078           26.444           23.584   \n",
       "111             0.112             0.084           22.611           21.404   \n",
       "99              0.233             0.084           52.328           44.512   \n",
       "119             0.101             0.088           16.956           15.988   \n",
       "47              0.129             0.091           24.831           22.911   \n",
       "35              0.196             0.093           45.083           37.596   \n",
       "11              0.369             0.102           72.451           57.570   \n",
       "15              0.138             0.105           22.384           20.704   \n",
       "42              0.286             0.107           68.059           59.331   \n",
       "3               0.266             0.108           52.998           43.285   \n",
       "115             0.190             0.109           41.920           35.131   \n",
       "79              0.129             0.116           22.319           21.391   \n",
       "91              0.377             0.123           76.621           62.757   \n",
       "95              0.147             0.133           26.417           25.854   \n",
       "71              0.163             0.160           31.664           31.788   \n",
       "67              0.193             0.172           38.362           37.294   \n",
       "55              0.194             0.193           31.040           31.148   \n",
       "83              0.340             0.200           59.826           53.690   \n",
       "158             0.214             0.202           28.945           27.916   \n",
       "159             0.211             0.203           27.939           27.157   \n",
       "23              0.286             0.204           53.400           48.438   \n",
       "157             0.221             0.213           28.742           27.960   \n",
       "156             0.226             0.216           29.852           28.898   \n",
       "28              0.261             0.236           38.226           36.169   \n",
       "126             0.249             0.238           35.896           34.983   \n",
       "127             0.250             0.239           36.294           35.184   \n",
       "125             0.251             0.240           36.637           35.648   \n",
       "103             0.292             0.242           64.353           60.628   \n",
       "76              0.259             0.247           32.421           31.516   \n",
       "36              0.266             0.250           31.759           30.448   \n",
       "124             0.267             0.258           35.056           34.145   \n",
       "0               0.421             0.276           59.704           50.079   \n",
       "151             0.275             0.277           41.521           41.758   \n",
       "12              0.308             0.280           38.990           36.810   \n",
       "134             0.285             0.286           39.826           39.968   \n",
       "132             0.286             0.287           39.764           40.006   \n",
       "133             0.285             0.288           38.579           38.821   \n",
       "135             0.295             0.296           40.419           40.659   \n",
       "4               0.323             0.297           40.292           38.619   \n",
       "44              0.324             0.312           41.396           40.418   \n",
       "68              0.336             0.324           48.395           47.840   \n",
       "147             0.333             0.324           48.757           47.867   \n",
       "148             0.326             0.330           46.295           46.694   \n",
       "144             0.340             0.331           45.756           44.866   \n",
       "150             0.327             0.331           47.429           47.828   \n",
       "75              0.397             0.336           60.760           55.160   \n",
       "145             0.352             0.343           48.990           48.100   \n",
       "52              0.366             0.343           45.949           44.841   \n",
       "116             0.361             0.347           38.923           37.703   \n",
       "146             0.363             0.354           49.864           48.944   \n",
       "149             0.351             0.355           45.937           46.335   \n",
       "63              0.424             0.376           62.499           59.095   \n",
       "59              0.443             0.400           82.498           80.624   \n",
       "20              0.478             0.423           72.652           68.151   \n",
       "24              0.462             0.443           58.063           57.037   \n",
       "84              0.474             0.460           52.814           51.579   \n",
       "92              0.486             0.463           53.000           51.695   \n",
       "142             0.501             0.467           70.862           67.531   \n",
       "32              0.526             0.474           69.959           64.927   \n",
       "51              0.561             0.485          105.315          100.376   \n",
       "155             0.567             0.515           75.734           70.584   \n",
       "143             0.551             0.522           84.251           81.321   \n",
       "64              0.553             0.545           67.346           66.456   \n",
       "43              0.598             0.569           82.941           80.350   \n",
       "108             0.592             0.582           65.476           65.060   \n",
       "154             0.640             0.586           84.784           79.525   \n",
       "152             0.658             0.608           87.515           82.514   \n",
       "153             0.688             0.637           86.063           81.023   \n",
       "40              0.776             0.678           93.539           85.336   \n",
       "16              0.741             0.700           99.669           96.659   \n",
       "104             0.719             0.701           76.253           74.637   \n",
       "140             0.733             0.702           94.095           90.980   \n",
       "121             0.733             0.708           91.440           88.944   \n",
       "122             0.741             0.711           92.046           89.079   \n",
       "120             0.741             0.715           93.881           91.379   \n",
       "123             0.754             0.729           93.477           90.936   \n",
       "141             0.779             0.750           94.159           91.229   \n",
       "136             0.771             0.764           98.153           97.531   \n",
       "60              0.815             0.780           98.679           95.349   \n",
       "138             0.795             0.789          106.718          106.243   \n",
       "72              0.871             0.821           97.454           92.487   \n",
       "80              0.930             0.832          100.252           92.373   \n",
       "137             0.883             0.878          111.867          111.405   \n",
       "139             0.891             0.884          108.347          107.751   \n",
       "129             1.018             0.916          137.415          129.971   \n",
       "130             1.007             0.975          133.152          130.062   \n",
       "112             1.026             0.977          107.715          102.748   \n",
       "100             1.034             0.981          111.421          107.543   \n",
       "8               1.078             1.014          137.942          132.900   \n",
       "131             1.053             1.021          139.366          136.237   \n",
       "128             1.084             1.048          139.251          136.035   \n",
       "56              1.083             1.051          122.103          119.577   \n",
       "48              1.230             1.179          147.663          143.590   \n",
       "96              1.226             1.191          133.095          131.066   \n",
       "88              1.667             1.610          176.863          172.500   \n",
       "\n",
       "     calibration_mse  sharpness  x_opt_dist_test  x_opt_dist_pool  \n",
       "18             0.013     -0.526            1.203            0.139  \n",
       "26             0.011     -0.312            1.397            0.324  \n",
       "17             0.016     -0.519            1.240            0.200  \n",
       "58             0.007     -0.500            1.335            0.166  \n",
       "97             0.017     -0.494            1.230            0.247  \n",
       "22             0.018     -0.446            1.581            0.380  \n",
       "66             0.006     -0.368            1.451            0.399  \n",
       "98             0.014     -0.349            1.283            0.097  \n",
       "102            0.017     -0.303            1.634            0.388  \n",
       "57             0.015     -0.465            1.227            0.274  \n",
       "10             0.018     -0.673            1.128            0.438  \n",
       "105            0.020     -0.332            1.533            0.344  \n",
       "62             0.008     -0.470            1.624            0.463  \n",
       "106            0.013     -0.171            1.514            0.318  \n",
       "29             0.023     -0.319            1.520            0.675  \n",
       "69             0.027     -0.294            1.459            0.467  \n",
       "30             0.014     -0.255            1.449            0.431  \n",
       "90             0.019     -0.549            1.166            0.475  \n",
       "34             0.023     -0.460            1.348            0.784  \n",
       "25             0.019     -0.349            1.500            0.340  \n",
       "70             0.008     -0.265            1.360            0.661  \n",
       "65             0.020     -0.340            1.450            0.525  \n",
       "110            0.012     -0.128            1.384            0.535  \n",
       "101            0.031     -0.447            1.647            0.734  \n",
       "61             0.026     -0.388            1.602            0.829  \n",
       "6              0.015     -0.241            1.759            0.892  \n",
       "21             0.027     -0.477            1.633            0.838  \n",
       "86             0.014     -0.152            1.782            0.928  \n",
       "109            0.025     -0.290            1.304            0.683  \n",
       "50             0.011     -0.712            1.168            0.481  \n",
       "2              0.021     -0.304            1.766            0.706  \n",
       "45             0.031     -0.252            1.868            1.168  \n",
       "85             0.034     -0.273            2.019            1.240  \n",
       "114            0.023     -0.304            1.359            0.802  \n",
       "38             0.017     -0.157            1.609            1.077  \n",
       "46             0.009     -0.452            1.760            1.167  \n",
       "73             0.030     -0.450            1.413            1.037  \n",
       "37             0.037     -0.300            1.810            1.204  \n",
       "118            0.017     -0.123            1.906            1.093  \n",
       "89             0.030     -0.609            1.240            0.483  \n",
       "14             0.022     -0.118            1.841            1.073  \n",
       "5              0.034     -0.287            2.024            1.304  \n",
       "27             0.025     -0.568            1.560            0.741  \n",
       "19             0.031     -0.661            1.186            0.646  \n",
       "74             0.014     -0.537            1.431            0.902  \n",
       "78             0.012     -0.406            1.691            1.225  \n",
       "41             0.030     -0.321            1.714            1.021  \n",
       "82             0.019     -0.311            1.814            0.855  \n",
       "33             0.032     -0.456            1.463            0.908  \n",
       "117            0.037     -0.257            1.738            1.341  \n",
       "81             0.032     -0.342            1.752            0.975  \n",
       "113            0.032     -0.454            1.388            0.954  \n",
       "77             0.032     -0.259            1.888            1.312  \n",
       "94             0.020     -0.243            1.925            1.129  \n",
       "9              0.029     -0.634            1.229            0.542  \n",
       "39             0.019     -0.227            1.786            1.497  \n",
       "1              0.032     -0.349            1.713            1.175  \n",
       "93             0.043     -0.199            1.890            1.410  \n",
       "53             0.040     -0.220            1.912            1.488  \n",
       "31             0.025     -0.506            1.349            1.207  \n",
       "49             0.027     -0.575            1.226            0.566  \n",
       "87             0.022     -0.354            1.924            1.555  \n",
       "7              0.023     -0.355            1.869            1.433  \n",
       "107            0.025     -0.569            1.499            1.173  \n",
       "13             0.041     -0.226            1.883            1.511  \n",
       "54             0.012     -0.370            1.916            1.245  \n",
       "111            0.026     -0.493            1.311            1.293  \n",
       "99             0.031     -0.651            1.280            0.747  \n",
       "119            0.022     -0.224            1.788            1.691  \n",
       "47             0.012     -0.396            1.920            1.714  \n",
       "35             0.028     -0.430            1.503            1.167  \n",
       "11             0.032     -0.563            1.314            0.810  \n",
       "15             0.019     -0.064            2.031            1.819  \n",
       "42             0.010     -0.447            1.886            0.881  \n",
       "3              0.023     -0.249            1.778            1.402  \n",
       "115            0.027     -0.453            1.301            1.329  \n",
       "79             0.011     -0.363            1.837            1.767  \n",
       "91             0.031     -0.533            1.306            0.961  \n",
       "95             0.017     -0.069            2.036            1.917  \n",
       "71             0.013     -0.521            1.701            1.447  \n",
       "67             0.009     -0.632            1.460            1.424  \n",
       "55             0.012     -0.210            2.015            2.018  \n",
       "83             0.020     -0.262            1.831            1.605  \n",
       "158            0.006     -0.179            2.000            1.808  \n",
       "159            0.007     -0.416            1.976            2.004  \n",
       "23             0.024     -0.500            1.580            1.031  \n",
       "157            0.009      0.063            2.186            1.903  \n",
       "156            0.090      1.237            1.988            1.937  \n",
       "28             0.083      0.858            1.744            1.622  \n",
       "126            0.008     -0.169            2.105            2.087  \n",
       "127            0.006     -0.407            1.921            1.920  \n",
       "125            0.010      0.126            1.998            1.983  \n",
       "103            0.024     -0.483            1.579            1.056  \n",
       "76             0.092      1.010            2.227            1.950  \n",
       "36             0.104      0.870            2.211            1.850  \n",
       "124            0.091      1.250            2.071            1.919  \n",
       "0              0.109      0.806            2.066            1.782  \n",
       "151            0.005     -0.582            1.787            1.676  \n",
       "12             0.129      0.811            2.087            2.032  \n",
       "134            0.007     -0.393            2.026            2.127  \n",
       "132            0.105      1.239            1.905            2.023  \n",
       "133            0.010      0.010            2.031            2.004  \n",
       "135            0.008     -0.265            1.882            2.033  \n",
       "4              0.103      0.923            2.045            1.721  \n",
       "44             0.094      1.060            1.973            2.025  \n",
       "68             0.082      0.940            1.725            1.528  \n",
       "147            0.005     -0.666            1.600            1.659  \n",
       "148            0.076      1.190            1.615            1.792  \n",
       "144            0.078      1.211            1.393            1.695  \n",
       "150            0.003     -0.102            1.690            1.780  \n",
       "75             0.015     -0.482            1.446            1.324  \n",
       "145            0.012     -0.022            1.633            1.775  \n",
       "52             0.115      0.986            2.345            2.177  \n",
       "116            0.117      0.682            2.306            2.150  \n",
       "146            0.003     -0.218            1.618            1.547  \n",
       "149            0.011      0.095            1.650            1.677  \n",
       "63             0.016     -0.558            1.519            1.366  \n",
       "59             0.013     -0.659            1.430            1.225  \n",
       "20             0.091      0.818            1.861            1.704  \n",
       "24             0.078      0.804            1.866            1.406  \n",
       "84             0.115      0.813            2.148            2.249  \n",
       "92             0.144      0.607            2.295            2.258  \n",
       "142            0.005     -0.214            1.518            1.662  \n",
       "32             0.094      0.865            1.839            1.608  \n",
       "51             0.015     -0.553            1.287            1.240  \n",
       "155            0.006     -0.556            1.581            1.640  \n",
       "143            0.006     -0.623            1.523            1.734  \n",
       "64             0.078      0.943            1.804            1.976  \n",
       "43             0.010     -0.352            1.900            1.867  \n",
       "108            0.096      0.601            1.999            1.716  \n",
       "154            0.005     -0.252            1.584            1.606  \n",
       "152            0.083      1.234            1.664            1.538  \n",
       "153            0.012      0.025            1.570            1.725  \n",
       "40             0.100      0.955            1.985            2.004  \n",
       "16             0.083      0.840            1.613            1.201  \n",
       "104            0.104      0.512            2.175            1.866  \n",
       "140            0.082      1.256            1.587            1.763  \n",
       "121            0.011      0.015            1.891            1.900  \n",
       "122            0.005     -0.290            1.902            1.828  \n",
       "120            0.094      1.250            2.008            1.866  \n",
       "123            0.007     -0.391            1.971            1.950  \n",
       "141            0.011      0.047            1.758            1.658  \n",
       "136            0.077      1.183            1.491            1.443  \n",
       "60             0.085      0.923            1.895            1.747  \n",
       "138            0.003     -0.153            1.428            1.562  \n",
       "72             0.084      0.996            1.758            1.834  \n",
       "80             0.129      0.506            2.225            2.123  \n",
       "137            0.012      0.056            1.607            1.575  \n",
       "139            0.005     -0.657            1.472            1.538  \n",
       "129            0.012     -0.087            1.461            1.447  \n",
       "130            0.006     -0.383            1.446            1.444  \n",
       "112            0.108      0.577            1.919            1.916  \n",
       "100            0.107      0.502            2.051            1.827  \n",
       "8              0.106      0.816            1.678            1.526  \n",
       "131            0.007     -0.552            1.452            1.448  \n",
       "128            0.093      1.240            1.430            1.464  \n",
       "56             0.079      0.969            1.609            1.600  \n",
       "48             0.100      0.978            1.686            1.585  \n",
       "96             0.093      0.575            1.652            1.472  \n",
       "88             0.123      0.538            1.932            1.839  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_rows', None,\n",
    "                       'display.max_columns', None,\n",
    "                       'display.precision', 3,\n",
    "                       ):\n",
    "    display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "505535c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Surrogate</th>\n",
       "      <th>Rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>2.074167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DE</td>\n",
       "      <td>2.118333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>2.943333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BNN</td>\n",
       "      <td>4.348611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Surrogate      Rank\n",
       "2        GP  2.074167\n",
       "1        DE  2.118333\n",
       "3        RF  2.943333\n",
       "0       BNN  4.348611"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Instantaneous regret of pool rankings of surrogates alone on synthetic data.\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "exp_dict = {'surrogate': [], 'acquisition': [], 'seed':[], 'problem_idx':[], 'dim':[], 'dist_nearest_train':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "main_directory=\"./results_synth_data/\"\n",
    "for foldername in os.listdir(main_directory):\n",
    "    folder = os.path.join(main_directory, foldername)\n",
    "    if os.path.isdir(folder):\n",
    "        for filename in os.listdir(folder):\n",
    "            if filename.find(\"parameters\") != -1:\n",
    "                json_file = open(os.path.join(folder, filename))\n",
    "                params = json.load(json_file)\n",
    "            elif filename.find(\"metrics\") != -1:\n",
    "                json_file = open(os.path.join(folder, filename))\n",
    "                metrics = json.load(json_file)\n",
    "        if params['bo'] == True:\n",
    "            exp_dict['surrogate'].append(params['surrogate'])\n",
    "            exp_dict['acquisition'].append(params['acquisition'])\n",
    "            exp_dict['problem_idx'].append(params['problem_idx'])\n",
    "            exp_dict['dim'].append(params['d'])\n",
    "            exp_dict['dist_nearest_train'].append(metrics['next_sample_train_distance'])\n",
    "            exp_dict['inst_regret_test'].append(metrics['y_regret_test'])\n",
    "            exp_dict['inst_regret_pool'].append(metrics['y_regret_pool'])\n",
    "            exp_dict['tot_regret_test'].append(np.cumsum(metrics['y_regret_test']))\n",
    "            exp_dict['tot_regret_pool'].append(np.cumsum(metrics['y_regret_pool']))\n",
    "            exp_dict['x_opt_dist_pool'].append(metrics['x_y_opt_dist_pool'])\n",
    "            exp_dict['x_opt_dist_test'].append(metrics['x_y_opt_dist_test'])\n",
    "            exp_dict['sharpness'].append(metrics['mean_sharpness'])\n",
    "            exp_dict['calibration_mse'].append(metrics['y_calibration_mse'])\n",
    "            exp_dict['seed'].append(params['seed'])\n",
    "df = pd.DataFrame.from_dict(exp_dict)\n",
    "processed_results = {'surrogate': [], 'acquisition': [], 'seed':[], 'problem_idx':[], 'dim':[], 'dist_nearest_train_mean':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for index, row in df.iterrows():\n",
    "    processed_results['surrogate'].append(row['surrogate'])\n",
    "    processed_results['acquisition'].append(row['acquisition'])\n",
    "    processed_results['problem_idx'].append(row['problem_idx'])\n",
    "    processed_results['dim'].append(row['dim'])\n",
    "    processed_results['seed'].append(row['seed'])\n",
    "    processed_results['dist_nearest_train_mean'].append(np.array(row['dist_nearest_train']).mean()) #Mean across one BO run.\n",
    "    processed_results['inst_regret_pool'].append(np.array(row['inst_regret_pool'])[-1]) #Last iter.\n",
    "    processed_results['inst_regret_test'].append(np.array(row['inst_regret_test'])[-1]) #Last iter.\n",
    "    processed_results['tot_regret_test'].append(np.array(row['tot_regret_test'])[-1]) #Last iter.\n",
    "    processed_results['tot_regret_pool'].append(np.array(row['tot_regret_pool'])[-1]) #Last iter.\n",
    "    processed_results['calibration_mse'].append(np.array(row['calibration_mse']).mean()) #Mean Calibration MSE over run.\n",
    "    processed_results['sharpness'].append(np.array(row['sharpness']).mean()) #Mean sharpness over run.\n",
    "    processed_results['x_opt_dist_test'].append(np.array(row['x_opt_dist_test'])[-1])\n",
    "    processed_results['x_opt_dist_pool'].append(np.array(row['x_opt_dist_pool'])[-1])\n",
    "#Same seed and same dataset are ranked together.\n",
    "df = pd.DataFrame.from_dict(processed_results)\n",
    "seeds = np.arange(10)+1\n",
    "problem_idxs = np.arange(10)+1\n",
    "acqs = ['UCB', 'TS', 'EI', 'RS']\n",
    "dimensions = np.arange(10)+1\n",
    "for seed in seeds:\n",
    "    for d in dimensions:\n",
    "        for problem_idx in problem_idxs:\n",
    "            for acq in acqs:\n",
    "                #For one problem and one seed, we get a ranking going from 1-16 (depending on ties) since there are 4 surrogates and 4 acqs.\n",
    "                selection = df.loc[(df['problem_idx']==problem_idx) & (df['seed']==seed) & (df['acquisition']==acq) & (df['dim']==d)]\n",
    "                df.loc[((df['problem_idx']==problem_idx) & (df['seed']==seed) & (df['acquisition']==acq) & (df['dim']==d)),'min_rank'] = selection['inst_regret_pool'].rank(method=\"min\")\n",
    "surrogates = ['BNN', 'DE', 'GP', 'RF']\n",
    "ranking_dict  = {'Surrogate':[], 'Rank':[]}\n",
    "for surrogate in surrogates:\n",
    "    ranking_dict['Rank'].append(df.loc[((df['surrogate']==surrogate)),'min_rank'].mean())\n",
    "    ranking_dict['Surrogate'].append(surrogate)\n",
    "display(pd.DataFrame.from_dict(ranking_dict).sort_values('Rank'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a89ac6a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-02, 1.62377674e-02, 2.63665090e-02, 4.28133240e-02,\n",
       "       6.95192796e-02, 1.12883789e-01, 1.83298071e-01, 2.97635144e-01,\n",
       "       4.83293024e-01, 7.84759970e-01, 1.27427499e+00, 2.06913808e+00,\n",
       "       3.35981829e+00, 5.45559478e+00, 8.85866790e+00, 1.43844989e+01,\n",
       "       2.33572147e+01, 3.79269019e+01, 6.15848211e+01, 1.00000000e+02])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ER STJ FOR HJ???\n",
    "#Eksempler hvor f_opt er -2 for eksempel, men y_opt er -2.7 (y = f + stj)\n",
    "#Syntetiske jobs - ndre dimensioner 2..10 step size 2\n",
    "#20 seeds, 20 problemer.\n",
    "import numpy as np\n",
    "np.exp(np.linspace(np.log(0.01), np.log(100), 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55751a6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
